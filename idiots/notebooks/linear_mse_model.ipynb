{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T00:07:59.330443695Z",
     "start_time": "2024-02-17T00:07:59.271265200Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=0.5\n",
    "# %env XLA_PYTHON_CLIENT_PREALLOCATE=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T00:08:00.786594472Z",
     "start_time": "2024-02-17T00:08:00.411064925Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import neural_tangents as nt\n",
    "\n",
    "from idiots.dataset.dataloader import DataLoader\n",
    "from idiots.experiments.grokking.training import restore, eval_step\n",
    "from idiots.utils import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(y, num_classes: int):\n",
    "    \"\"\"Takes inputs of shape (n) -> (n k) where k is the number of classes\n",
    "\n",
    "    Also centers the labels so that the mean is zero.\n",
    "    \"\"\"\n",
    "    y = jax.nn.one_hot(y, num_classes)\n",
    "    y = y - jnp.mean(y, axis=0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses_after_ntk_descent(\n",
    "    init_state,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_size: int,\n",
    "    test_size: int,\n",
    "):\n",
    "    # Load and preprocess the data\n",
    "    x_train = ds_train[\"x\"][:train_size]\n",
    "    y_train_raw = ds_train[\"y\"][:train_size]\n",
    "    y_train = preprocess_labels(\n",
    "        y_train_raw, num_classes=ds_train.features[\"y\"].num_classes\n",
    "    )\n",
    "    x_test = ds_test[\"x\"][:test_size]\n",
    "    y_test_raw = ds_test[\"y\"][:test_size]\n",
    "    y_test = preprocess_labels(\n",
    "        y_test_raw, num_classes=ds_test.features[\"y\"].num_classes\n",
    "    )\n",
    "\n",
    "    # Perform kernel descent\n",
    "    @partial(nt.batch, batch_size=64, store_on_device=True)\n",
    "    def kernel_fn(x1, x2, params):\n",
    "        k = nt.empirical_ntk_fn(init_state.apply_fn, trace_axes=(), vmap_axes=0)(\n",
    "            x1, x2, params\n",
    "        )\n",
    "        return k\n",
    "\n",
    "    k_train_train = kernel_fn(x_train, x_train, init_state.params)\n",
    "    predict_fn = nt.predict.gradient_descent_mse(\n",
    "        k_train_train, y_train, trace_axes=(), diag_reg=1e-3\n",
    "    )\n",
    "\n",
    "    # Make the predictions\n",
    "    y_train_0 = init_state.apply_fn(init_state.params, x_train)\n",
    "    y_test_0 = init_state.apply_fn(init_state.params, x_test)\n",
    "    k_test_train = kernel_fn(x_test, x_train, init_state.params)\n",
    "    y_train_t, y_test_t = predict_fn(None, y_train_0, y_test_0, k_test_train)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    y_pred_train = jnp.argmax(y_train_t, axis=-1)\n",
    "    y_pred_test = jnp.argmax(y_test_t, axis=-1)\n",
    "    acc_train = jnp.mean(y_pred_train == y_train_raw)\n",
    "    acc_test = jnp.mean(y_pred_test == y_test_raw)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss_train = jnp.mean(jnp.square(y_train_t - y_train))\n",
    "    loss_test = jnp.mean(jnp.square(y_test_t - y_test))\n",
    "\n",
    "    return loss_train, loss_test, acc_train, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = Path(\"/home/dc755/idiots/logs/grokking/exp22/checkpoints\")\n",
    "checkpoint_dir = Path(\"logs/grokking/exp22/checkpoints\")\n",
    "\n",
    "\n",
    "def checkpoint_ntk_descent_losses(step: int):\n",
    "    config, state, ds_train, ds_test = restore(checkpoint_dir, step)\n",
    "\n",
    "    loss_train, loss_test, acc_train, acc_test = losses_after_ntk_descent(\n",
    "        state, ds_train, ds_test, train_size=256, test_size=128\n",
    "    )\n",
    "    return loss_train.item(), loss_test.item(), acc_train.item(), acc_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for step in range(5000, 20000, 1000):\n",
    "    loss_train, loss_test, acc_train, acc_test = checkpoint_ntk_descent_losses(step)\n",
    "    print(step, loss_test, acc_test)  # print to make sure they're not NaN\n",
    "    data.append({\"step\": step, \"split\": \"train\", \"loss\": loss_train, \"acc\": acc_train})\n",
    "    data.append({\"step\": step, \"split\": \"test\", \"loss\": loss_test, \"acc\": acc_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "ax = sns.lineplot(data=df, x=\"step\", y=\"acc\", hue=\"split\", marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "\n",
    "def eval_checkpoint(step):\n",
    "    config, state, ds_train, ds_test = restore(checkpoint_dir, step)\n",
    "\n",
    "    def eval_loss_acc(ds):\n",
    "        for batch in DataLoader(ds, batch_size):\n",
    "            logs = eval_step(state, batch, config.loss_variant)\n",
    "            metrics.log(**logs)\n",
    "        [losses, accuracies] = metrics.collect(\"eval_loss\", \"eval_accuracy\")\n",
    "        loss = jnp.concatenate(losses).mean().item()\n",
    "        acc = jnp.concatenate(accuracies).mean().item()\n",
    "        return loss, acc\n",
    "\n",
    "    train_loss, train_acc = eval_loss_acc(ds_train)\n",
    "    test_loss, test_acc = eval_loss_acc(ds_test)\n",
    "\n",
    "    return train_loss, train_acc, test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_losses_data = []\n",
    "for step in range(5000, 20000, 1000):\n",
    "    train_loss, train_acc, test_loss, test_acc = eval_checkpoint(step)\n",
    "    raw_losses_data.append(\n",
    "        {\"step\": step, \"split\": \"train\", \"loss\": train_loss, \"acc\": train_acc}\n",
    "    )\n",
    "    raw_losses_data.append(\n",
    "        {\"step\": step, \"split\": \"test\", \"loss\": test_loss, \"acc\": test_acc}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 6), sharey=\"row\")\n",
    "axs = axs.flatten()\n",
    "df_raw = pd.DataFrame(raw_losses_data)\n",
    "df_ntk = pd.DataFrame(data)\n",
    "\n",
    "sns.lineplot(data=df_raw, x=\"step\", y=\"acc\", hue=\"split\", marker=\"o\", ax=axs[0])\n",
    "sns.lineplot(data=df_ntk, x=\"step\", y=\"acc\", hue=\"split\", marker=\"o\", ax=axs[1])\n",
    "sns.lineplot(data=df_raw, x=\"step\", y=\"loss\", hue=\"split\", marker=\"o\", ax=axs[2])\n",
    "sns.lineplot(data=df_ntk, x=\"step\", y=\"loss\", hue=\"split\", marker=\"o\", ax=axs[3])\n",
    "\n",
    "axs[0].set(title=\"Training curve\", ylabel=\"Accuracy\")\n",
    "axs[1].set(title=\"NTK descent (infinite time) curve\")\n",
    "axs[2].set(ylabel=\"MSE\")\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idiots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
