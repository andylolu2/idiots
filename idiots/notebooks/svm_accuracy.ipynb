{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from idiots.dataset.dataloader import DataLoader\n",
    "from idiots.experiments.grokking.training import restore, eval_step\n",
    "from idiots.utils import metrics\n",
    "import neural_tangents as nt\n",
    "from einops import rearrange\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = Path(\"../../logs/division/exp21/checkpoints\")\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "def eval_checkpoint(step):\n",
    "    config, state, ds_train, ds_test = restore(checkpoint_dir, step)\n",
    "\n",
    "    def eval_loss_acc(ds):\n",
    "        for batch in DataLoader(ds, batch_size):\n",
    "            logs = eval_step(state, batch, config.loss_variant)\n",
    "            metrics.log(**logs)\n",
    "        [losses, accuracies] = metrics.collect(\"eval_loss\", \"eval_accuracy\")\n",
    "        loss = jnp.concatenate(losses).mean().item()\n",
    "        acc = jnp.concatenate(accuracies).mean().item()\n",
    "        return loss, acc\n",
    "\n",
    "    train_loss, train_acc = eval_loss_acc(ds_train)\n",
    "    test_loss, test_acc = eval_loss_acc(ds_test)\n",
    "\n",
    "    return state, ds_train, ds_test, train_loss, train_acc, test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for step in range(0, 50000, 10000):\n",
    "    (\n",
    "        state,\n",
    "        ds_train,\n",
    "        ds_test,\n",
    "        train_loss,\n",
    "        train_acc,\n",
    "        test_loss,\n",
    "        test_acc,\n",
    "    ) = eval_checkpoint(step)\n",
    "    data.append(\n",
    "        {\n",
    "            \"step\": step,\n",
    "            \"state\": state,\n",
    "            \"ds_train\": ds_train,\n",
    "            \"ds_test\": ds_test,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_loss = df[[\"step\", \"train_loss\", \"test_loss\"]]\n",
    "df_loss = df_loss.melt(\"step\", var_name=\"split\", value_name=\"loss\")\n",
    "df_loss[\"split\"] = df_loss[\"split\"].str.replace(\"_loss\", \"\")\n",
    "\n",
    "\n",
    "df_acc = df[[\"step\", \"train_acc\", \"test_acc\"]]\n",
    "df_acc = df_acc.melt(\"step\", var_name=\"split\", value_name=\"accuracy\")\n",
    "df_acc[\"split\"] = df_acc[\"split\"].str.replace(\"_acc\", \"\")\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# sns.lineplot(data=df_loss, x=\"step\", y=\"loss\", hue=\"split\", marker=\"o\", ax=axs[0])\n",
    "# sns.lineplot(data=df_acc, x=\"step\", y=\"accuracy\", hue=\"split\", marker=\"o\", ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = df_loss[df_loss[\"split\"] == \"train\"][\"loss\"].tolist()\n",
    "test_loss = df_loss[df_loss[\"split\"] == \"test\"][\"loss\"].tolist()\n",
    "training_acc = df_acc[df_acc[\"split\"] == \"train\"][\"accuracy\"].tolist()\n",
    "test_acc = df_acc[df_acc[\"split\"] == \"test\"][\"accuracy\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dots(kernel_fn, X):\n",
    "    kernel_fn_batched = nt.batch(kernel_fn, device_count=-1, batch_size=32)\n",
    "    kernel = kernel_fn_batched(X, None, \"ntk\", state.params)\n",
    "    return jnp.linalg.matrix_rank(kernel).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "state_checkpoints = df[\"state\"].tolist()\n",
    "train_data_checkpoints = df[\"ds_train\"].tolist()\n",
    "test_data_checkpoints = df[\"ds_test\"].tolist()\n",
    "\n",
    "svm_accuracy = []\n",
    "dots_results = []\n",
    "\n",
    "N_train = 10  # 512\n",
    "N_test = 10  # 512\n",
    "\n",
    "X_train = jnp.array(train_data_checkpoints[0][\"x\"][:N_train])\n",
    "Y_train = jnp.array(train_data_checkpoints[0][\"y\"][:N_train])\n",
    "\n",
    "X_test = jnp.array(test_data_checkpoints[0][\"x\"][:N_test])\n",
    "Y_test = jnp.array(test_data_checkpoints[0][\"y\"][:N_test])\n",
    "\n",
    "for i in range(len(state_checkpoints)):\n",
    "    print(f\"Iteration: {i}/{len(state_checkpoints)}\")\n",
    "\n",
    "    state = state_checkpoints[i]\n",
    "\n",
    "    kernel_fn = nt.empirical_kernel_fn(\n",
    "        state.apply_fn,\n",
    "        vmap_axes=0,\n",
    "        implementation=nt.NtkImplementation.STRUCTURED_DERIVATIVES,\n",
    "    )\n",
    "\n",
    "    dots = get_dots(kernel_fn, X_test)\n",
    "\n",
    "    def custom_kernel(X1, X2):\n",
    "        kernel_fn_batched = nt.batch(kernel_fn, device_count=-1, batch_size=32)\n",
    "        return kernel_fn_batched(X1, X2, \"ntk\", state.params)\n",
    "\n",
    "    svc = SVC(kernel=custom_kernel)\n",
    "\n",
    "    svc.fit(X_train, Y_train)\n",
    "\n",
    "    predictions = svc.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "\n",
    "    svm_accuracy.append(accuracy)\n",
    "    dots_results.append(dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_loss)\n",
    "print(test_loss)\n",
    "print(svm_accuracy)\n",
    "print(dots_results)\n",
    "\n",
    "graph_data = {\n",
    "    \"training_loss\": training_loss,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"training_acc\": train_acc,\n",
    "    \"test_acc\": test_acc,\n",
    "    \"svm_accuracy\": svm_accuracy,\n",
    "    \"dots\": dots_results,\n",
    "}\n",
    "\n",
    "json_data = json.dumps(graph_data, indent=2)\n",
    "\n",
    "with open(\"graph_data.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
    "\n",
    "for i, exp in enumerate([\"div\", \"div_mse\", \"s5\"]):\n",
    "    with open(f\"results_{exp}.json\", \"r\") as json_file:\n",
    "        df = pd.read_json(json_file)\n",
    "    df[\"step\"] = df.index * 1000\n",
    "    df = df[[\"step\", \"training_acc\", \"test_acc\", \"svm_accuracy\"]]\n",
    "    df = df.melt(\"step\", var_name=\"type\", value_name=\"Accuracy\")\n",
    "\n",
    "    sns.lineplot(data=df, x=\"step\", y=\"Accuracy\", hue=\"type\", marker=\"o\", ax=axs[i])\n",
    "    axs[i].set(title=exp, xlabel=\"Step\", ylabel=\"Accuracy\")\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
