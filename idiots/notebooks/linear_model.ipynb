{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T00:07:59.330443695Z",
     "start_time": "2024-02-17T00:07:59.271265200Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env XLA_PYTHON_CLIENT_MEM_FRACTION=0.95\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T00:08:00.786594472Z",
     "start_time": "2024-02-17T00:08:00.411064925Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import cast\n",
    "from copy import deepcopy\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import neural_tangents as nt\n",
    "import optax\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from idiots.dataset.dataloader import DataLoader\n",
    "from idiots.experiments.grokking.training import (\n",
    "    restore as restore_grokking,\n",
    "    train_step,\n",
    "    eval_step,\n",
    "    TrainState,\n",
    "    loss_fn,\n",
    ")\n",
    "from idiots.experiments.classification.training import (\n",
    "    restore as restore_classification,\n",
    "    restore_partial as restore_partial_classification,\n",
    ")\n",
    "from idiots.utils import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T00:08:02.987182712Z",
     "start_time": "2024-02-17T00:08:02.952034256Z"
    }
   },
   "outputs": [],
   "source": [
    "# checkpoint_dir = Path(\"/home/dc755/idiots/logs/grokking/exp22/checkpoints\")\n",
    "checkpoint_dir = Path(\"logs/checkpoints/mnist/exp55/checkpoints\")\n",
    "\n",
    "# def linear_model_from(step):\n",
    "mngr, config, state, ds_train, ds_test = restore_classification(checkpoint_dir, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_state = TrainState.create(\n",
    "    apply_fn=nt.linearize(state.apply_fn, state.params),\n",
    "    params=state.params,\n",
    "    tx=state.tx,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    ds_train, config.train_batch_size, shuffle=True, infinite=True, drop_last=True\n",
    ")\n",
    "train_iter = iter(train_loader)\n",
    "\n",
    "while linear_state.step < 2000:\n",
    "    linear_state, logs = train_step(linear_state, next(train_iter), config.loss_variant)\n",
    "    linear_state = cast(TrainState, linear_state)  # For better typing\n",
    "    metrics.log(**logs)\n",
    "\n",
    "    if linear_state.step % 100 == 0:\n",
    "        [losses, accuracies] = metrics.collect(\"loss\", \"accuracy\")\n",
    "        loss = jnp.concatenate(losses).mean().item()\n",
    "        acc = jnp.concatenate(accuracies).mean().item()\n",
    "        print(f\"Train {loss=} {acc=}\")\n",
    "\n",
    "    if linear_state.step % 200 == 0:\n",
    "        for batch in DataLoader(ds_test, config.test_batch_size):\n",
    "            logs = eval_step(linear_state, batch, config.loss_variant)\n",
    "            metrics.log(**logs)\n",
    "        [losses, accuracies] = metrics.collect(\"eval_loss\", \"eval_accuracy\")\n",
    "        loss = jnp.concatenate(losses).mean().item()\n",
    "        acc = jnp.concatenate(accuracies).mean().item()\n",
    "        print(f\"Eval {loss=} {acc=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an ODE solver (not working, takes too much memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(nt.batch, batch_size=64, store_on_device=True)  # type: ignore\n",
    "def kernel_fn(x1, x2, params):\n",
    "    k = nt.empirical_ntk_fn(state.apply_fn, trace_axes=(), vmap_axes=0)(x1, x2, params)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 128\n",
    "# test_size = 128\n",
    "\n",
    "x_train, _, y_train, _ = train_test_split(\n",
    "    ds_train[\"x\"], ds_train[\"y\"], train_size=train_size, stratify=ds_train[\"y\"]\n",
    ")\n",
    "# x_test = ds_test[\"x\"][:test_size]\n",
    "\n",
    "k_train_train = kernel_fn(x_train, x_train, state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_y(y):\n",
    "    return jax.nn.one_hot(y, num_classes=ds_train.features[\"y\"].num_classes)\n",
    "\n",
    "\n",
    "# y_train = jax.nn.one_hot(y_train, num_classes=ds_train.features[\"y\"].num_classes)\n",
    "# y_train = y_train.astype(jnp.float32)\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nt.predict.gradient_descent\n",
    "# def cross_entropy(fx, y_hat):\n",
    "#     return -jnp.mean(jax.nn.log_softmax(fx) * y_hat)\n",
    "\n",
    "\n",
    "def mse(fx, y):\n",
    "    y = y - jnp.mean(y, axis=-1, keepdims=True)\n",
    "    return jnp.mean(jnp.square(fx - y))\n",
    "\n",
    "\n",
    "# loss = partial(loss_fn, variant=\"mse\")\n",
    "predict_fn = nt.predict.gradient_descent(\n",
    "    mse, k_train_train, preprocess_y(y_train), trace_axes=()\n",
    ")\n",
    "\n",
    "# y_train_mse = y_train - jnp.mean(y_train)\n",
    "# predict_fn = nt.predict.gradient_descent_mse(k_train_train, y_train_mse, trace_axes=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_train_0 = state.apply_fn(state.params, x_train)\n",
    "predict_fn(None, fx_train_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idiots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
