{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import neural_tangents as nt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import orbax.checkpoint as ocp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from einops import rearrange\n",
    "\n",
    "from idiots.experiments.compute_results.compute_results import restore_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = Path(\"logs/checkpoints/gradient_flow/exp34/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/mnist/exp66/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/mnist/exp75/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/mnist/mnist_gd_grokking/checkpoints\")\n",
    "checkpoint_dir = Path(\"logs/checkpoints/gradient_flow/exp39/checkpoints\")\n",
    "config, apply_fn, get_params, ds_train, ds_test, all_steps = restore_checkpoint(\n",
    "    checkpoint_dir,\n",
    "    experiment_type=\"gradient_flow_\",\n",
    "    # experiment_type=\"mnist\",\n",
    "    # experiment_type=\"grokking\",\n",
    ")\n",
    "\n",
    "\n",
    "def kernel_fn(x, params):\n",
    "    k = nt.batch(\n",
    "        nt.empirical_ntk_fn(\n",
    "            apply_fn,\n",
    "            vmap_axes=0,\n",
    "            trace_axes=(),\n",
    "            implementation=nt.NtkImplementation.STRUCTURED_DERIVATIVES,\n",
    "        ),\n",
    "        batch_size=64,\n",
    "    )(x, None, params)\n",
    "    k = rearrange(k, \"b1 b2 d1 d2 -> (b1 d1) (b2 d2)\")\n",
    "    return k\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def kernel_distance(k1, k2):\n",
    "    return 1 - (\n",
    "        jnp.trace(k1 @ k2.T)\n",
    "        / (jnp.sqrt(jnp.trace(k1 @ k1.T)) * jnp.sqrt(jnp.trace(k2 @ k2.T)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = jnp.concatenate([ds_train[\"x\"], ds_test[\"x\"]], axis=0)\n",
    "ys = jnp.concatenate([ds_train[\"y\"], ds_test[\"y\"]], axis=0)\n",
    "x, _, y, _ = train_test_split(xs, ys, train_size=128, stratify=ys)\n",
    "\n",
    "data = []\n",
    "\n",
    "prev_kernel = kernel_fn(x, get_params(0))\n",
    "for step in all_steps[1:]:\n",
    "    kernel = kernel_fn(x, get_params(step))\n",
    "    data.append({\"step\": step, \"distance\": kernel_distance(prev_kernel, kernel).item()})\n",
    "    prev_kernel = kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"velocity\"] = df[\"distance\"] / (df[\"step\"] - df[\"step\"].shift(1, fill_value=0))\n",
    "\n",
    "with plt.style.context([\"science\", \"grid\"]):\n",
    "    fig, ax = plt.subplots(figsize=(3, 2.6))\n",
    "    sns.lineplot(data=df, x=\"step\", y=\"velocity\", ax=ax)\n",
    "    ax.set(ylim=(0, 1e-5), ylabel=\"Kernel velocity\", xlabel=\"$t$\")\n",
    "\n",
    "    # fig.savefig(\"logs/plots/gradient_flow_velocity.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idiots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
