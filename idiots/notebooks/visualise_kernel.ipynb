{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import neural_tangents as nt\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from einops import rearrange\n",
    "\n",
    "# from idiots.experiments.classification.training import restore\n",
    "from idiots.experiments.grokking.training import restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = Path(\"logs/mnist/mnist_adamw/checkpoints\")\n",
    "checkpoint_dir = Path(\"logs/grokking/division_47/checkpoints\")\n",
    "config, state, ds_train, ds_test = restore(checkpoint_dir, step=10000)\n",
    "n_classes = ds_train.features[\"y\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_fn = nt.empirical_ntk_fn(\n",
    "    state.apply_fn,\n",
    "    trace_axes=(),\n",
    "    vmap_axes=0,\n",
    "    implementation=nt.NtkImplementation.STRUCTURED_DERIVATIVES,\n",
    ")\n",
    "\n",
    "\n",
    "def ntk(x1, x2):\n",
    "    x2 = None if x1 is x2 else x2\n",
    "    k = nt.batch(kernel_fn, batch_size=64)(x1, x2, state.params)\n",
    "    # k = rearrange(k, \"b1 b2 d1 d2 -> (b1 d1) (b2 d2)\")\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "samples = ds_test.shuffle().select(range(128))\n",
    "x, y = samples[\"x\"], samples[\"y\"]\n",
    "order_ = np.argsort(y)\n",
    "x, y = x[order_], y[order_]\n",
    "\n",
    "K = ntk(x, x)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic\n",
    "samples = jnp.concat([ds_train[\"x\"], ds_test[\"x\"]], axis=0)\n",
    "samples = samples[samples[:, 0] == 4]\n",
    "order_ = np.argsort(samples[:, 2])\n",
    "x = samples[order_]\n",
    "\n",
    "K = ntk(x, x)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_reduced = jnp.mean(K, axis=(-2, -1))\n",
    "K_reduced = jnp.mean(K, axis=(0, 1))\n",
    "# K_reduced = K[-2, -2]\n",
    "print(f\"{K_reduced.shape=}\")\n",
    "y_pred = jnp.argmax(state.apply_fn(state.params, x), axis=-1)\n",
    "print(f\"{y_pred=}\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 6), gridspec_kw={\"height_ratios\": [1, 10]})\n",
    "# axs[0].imshow(rearrange(x, \"b h w -> h (b w)\"), aspect=\"equal\", cmap=\"gray\")\n",
    "sns.heatmap(K_reduced, ax=axs[1], square=True, cmap=\"RdBu\", center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "samples = ds_test.shuffle().select(range(n))\n",
    "xs, ys = samples[\"x\"], samples[\"y\"]\n",
    "ys_pred = jnp.argmax(state.apply_fn(state.params, xs), axis=-1)\n",
    "\n",
    "# plot the confusion matrix\n",
    "confusion_matrix = pd.crosstab(ys, ys_pred, rownames=[\"True\"], colnames=[\"Predicted\"])\n",
    "# remove the diagonal\n",
    "confusion_matrix.values[np.arange(10), np.arange(10)] = 0\n",
    "sns.heatmap(confusion_matrix, annot=True, square=True, fmt=\"d\", cmap=\"RdBu\", center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_flat = rearrange(K, \"b1 b2 d1 d2 -> (b1 d1) (b2 d2)\")\n",
    "lambda_, es = jnp.linalg.eigh(K_flat)\n",
    "print(jnp.linalg.matrix_rank(K_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.lineplot(lambda_[::-1], ax=ax)\n",
    "ax.set(yscale=\"log\")\n",
    "\n",
    "# print(lambda_[-1])\n",
    "# sns.heatmap(e1, ax=ax, cmap=\"RdBu\", center=0)\n",
    "# ax.set(yticks=[])\n",
    "\n",
    "# eig_idx = -6\n",
    "# e = rearrange(es[:, eig_idx], \"(b d) -> b d\", d=10)\n",
    "# e_max_idx = jnp.argmax(jnp.abs(e), axis=1)\n",
    "# e_max = jnp.abs(e)[jnp.arange(e.shape[0]), e_max_idx]\n",
    "# e_max_sign = e[jnp.arange(e.shape[0]), e_max_idx]\n",
    "# top_samples = jnp.argsort(e_max)[-20:]\n",
    "\n",
    "# img = x[top_samples] * rearrange(e_max_sign[top_samples], \"b -> b 1 1\")\n",
    "# img = rearrange(img[::-1], \"b h w -> h (b w)\")\n",
    "# v = jnp.max(jnp.abs(img))\n",
    "# ax.imshow(img, aspect=\"equal\", cmap=\"RdBu\", vmin=-v, vmax=v)\n",
    "# ax.set(xticks=[], yticks=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idiots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
