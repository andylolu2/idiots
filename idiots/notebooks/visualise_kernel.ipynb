{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import jax\n",
    "import neural_tangents as nt\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from einops import rearrange\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import scienceplots\n",
    "\n",
    "from idiots.experiments.compute_results.compute_results import restore_checkpoint\n",
    "\n",
    "plt.style.use([\"science\", \"grid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = Path(\"logs/checkpoints/mnist/mnist_grokking_slower/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/mnist/mnist_gd_grokking/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/grokking/division_47/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/gradient_flow/exp63/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/grokking/exp112/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/grokking/exp123/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/mnist/mnist_adamw/checkpoints/\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/grokking/division_adamw_mlp/checkpoints/\")\n",
    "# checkpoint_dir = Path(\n",
    "#     \"logs/checkpoints/grokking/division_adamw_transformer/checkpoints/\"\n",
    "# )\n",
    "checkpoint_dir = Path(\n",
    "    \"logs/checkpoints/grokking/division_adamw_mlp_1_layer/checkpoints/\"\n",
    ")\n",
    "\n",
    "config, apply_fn, get_params, ds_train, ds_test, all_steps = restore_checkpoint(\n",
    "    checkpoint_dir,\n",
    "    # experiment_type=\"gradient_flow_mnist\",\n",
    "    # experiment_type=\"mnist\",\n",
    "    experiment_type=\"algorithmic\",\n",
    ")\n",
    "n_classes = ds_train.features[\"y\"].num_classes\n",
    "\n",
    "\n",
    "def kernel_traced_fn(x, params):\n",
    "    k = nt.batch(\n",
    "        nt.empirical_ntk_fn(\n",
    "            apply_fn,\n",
    "            vmap_axes=0,\n",
    "            trace_axes=(-1,),\n",
    "            implementation=nt.NtkImplementation.STRUCTURED_DERIVATIVES,\n",
    "        ),\n",
    "        batch_size=config.dots_batch_size,\n",
    "    )(x, None, params)\n",
    "    return k\n",
    "\n",
    "\n",
    "def kernel_fn(x, params):\n",
    "    k = nt.batch(\n",
    "        nt.empirical_ntk_fn(\n",
    "            apply_fn,\n",
    "            vmap_axes=0,\n",
    "            trace_axes=(),\n",
    "            implementation=nt.NtkImplementation.STRUCTURED_DERIVATIVES,\n",
    "        ),\n",
    "        batch_size=config.dots_batch_size,\n",
    "    )(x, None, params)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "x, _, y, _ = train_test_split(\n",
    "    ds_test[\"x\"], ds_test[\"y\"], train_size=128, stratify=ds_test[\"y\"]\n",
    ")\n",
    "order_ = np.argsort(y)\n",
    "x, y = x[order_], y[order_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, 2000, 11, dtype=int)\n",
    "\n",
    "fig, axs = plt.subplots(1, len(ts), figsize=(16, 6))\n",
    "\n",
    "# Ks = [kernel_fn(x, get_params(t)).mean((-2, -1)) for t in ts]\n",
    "Ks = [kernel_traced_fn(x, get_params(t)) for t in ts]\n",
    "\n",
    "for ax, t, K in zip(axs, ts, Ks):\n",
    "    # vabs = max(abs(K.min()), abs(K.max()))\n",
    "    ax.imshow(K, cmap=\"RdBu\")\n",
    "    ax.set_title(f\"t={t}\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic\n",
    "x = jnp.concat([ds_train[\"x\"], ds_test[\"x\"]], axis=0)\n",
    "y = jnp.concat([ds_train[\"y\"], ds_test[\"y\"]], axis=0)\n",
    "order_ = np.lexsort((x[:, 2], x[:, 0], y))\n",
    "x = x[order_]\n",
    "y = y[order_]\n",
    "\n",
    "# indices = np.arange(1024, 1536)\n",
    "indices = np.random.choice(len(x), 256, replace=False)\n",
    "x, y = x[indices], y[indices]\n",
    "\n",
    "K = kernel_fn(x, get_params(50000))\n",
    "K.shape, K.min(), K.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_reduced = K\n",
    "K_reduced = jnp.mean(K, axis=(-2, -1))\n",
    "# K_reduced = jnp.mean(K, axis=(0, 1))\n",
    "# K_reduced = K[0, 0]\n",
    "print(f\"{K_reduced.shape=}\")\n",
    "# y_pred = jnp.argmax(apply_fn(params, x), axis=-1)\n",
    "# print(f\"{y_pred=}\")\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(10, 6), gridspec_kw={\"height_ratios\": [1, 10]})\n",
    "# axs[0].imshow(rearrange(x, \"b h w -> h (b w)\"), aspect=\"equal\", cmap=\"gray\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "# labels = x[:, [0, 2]].tolist()\n",
    "ax.imshow(K_reduced, cmap=\"RdBu\")\n",
    "ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_params(100000)\n",
    "jax.tree_map(lambda x: x.shape, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_params(100000)\n",
    "# E = params[\"params\"][\"Embed_0\"][\"embedding\"]\n",
    "E = params[\"params\"][\"Dense_2\"][\"kernel\"].T\n",
    "# E = params[\"params\"][\"Dense_0\"][\"kernel\"].T\n",
    "print(f\"{E.shape=}\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "E = pca.fit_transform(E)\n",
    "# tsne = TSNE(n_components=2, perplexity=30, n_iter=1000)\n",
    "# E = tsne.fit_transform(E)\n",
    "print(f\"{E.shape=}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.scatter(x=E[:, 0], y=E[:, 1], c=np.arange(len(E)))\n",
    "\n",
    "idx_1 = np.arange(len(E))\n",
    "idx_2 = len(E) - idx_1\n",
    "idx_2[0] = 0\n",
    "print(np.stack([idx_1, idx_2]))\n",
    "for x1, y1, x2, y2 in zip(E[idx_1, 0], E[idx_1, 1], E[idx_2, 0], E[idx_2, 1]):\n",
    "    ax.plot([x1, x2], [y1, y2], color=\"black\", alpha=0.1)\n",
    "\n",
    "for i, (x, y) in enumerate(E):\n",
    "    ax.text(x, y, str(i), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idiots.dataset.algorithmic import OPERATIONS\n",
    "\n",
    "op = OPERATIONS[\"x / y (mod 47)\"]\n",
    "x = range(op[\"n_classes\"])\n",
    "\n",
    "\n",
    "# print table\n",
    "table = [[(i * j) % len(x) for j in x] for i in x]\n",
    "df = pd.DataFrame(table, index=x, columns=x)\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(df)\n",
    "\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "# table = [[op[\"fn\"](i, j) for j in x] for i in x]\n",
    "# axs[0, 0].imshow(table, cmap=\"RdBu\")\n",
    "# table = [[op[\"fn\"](i, j) for j in reversed(x)] for i in x]\n",
    "# axs[0, 1].imshow(table, cmap=\"RdBu\")\n",
    "# table = [[op[\"fn\"](i, j) for j in x] for i in reversed(x)]\n",
    "# axs[1, 0].imshow(table, cmap=\"RdBu\")\n",
    "# table = [[op[\"fn\"](i, j) for j in reversed(x)] for i in reversed(x)]\n",
    "# axs[1, 1].imshow(table, cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST representations and kernel evolution\n",
    "\n",
    "X, _, Y, _ = train_test_split(\n",
    "    ds_test[\"x\"], ds_test[\"y\"], train_size=512, stratify=ds_test[\"y\"]\n",
    ")\n",
    "order_ = np.argsort(Y)\n",
    "X, Y = X[order_], Y[order_]\n",
    "\n",
    "ts = range(0, 100000 + 1, 20000)\n",
    "\n",
    "fig, axs = plt.subplots(2, len(ts), figsize=(2 * len(ts), 4), squeeze=False)\n",
    "\n",
    "for axs_, t in zip(axs.T, ts):\n",
    "    ax1, ax2 = axs_[0], axs_[1]\n",
    "    params = get_params(t)\n",
    "    W_1 = params[\"params\"][\"Dense_0\"][\"kernel\"]\n",
    "    b_1 = params[\"params\"][\"Dense_0\"][\"bias\"]\n",
    "    E = jax.nn.relu(X.reshape(len(X), -1) / 255 @ W_1 + b_1)\n",
    "    pca = PCA(n_components=2)\n",
    "    E = pca.fit_transform(E)\n",
    "    v1, v2 = pca.explained_variance_ratio_\n",
    "\n",
    "    ax1.scatter(x=E[:, 0], y=E[:, 1], c=Y, cmap=\"tab10\", alpha=0.7, s=5)\n",
    "    ax1.set(xticks=[], yticks=[], aspect=1 / ax1.get_data_ratio())\n",
    "    ax1.set_xlabel(f\"PCA 1: {v1*100:.2f}\\%\", fontsize=\"small\")\n",
    "    ax1.set_ylabel(f\"PCA 2: {v2*100:.2f}\\%\", fontsize=\"small\")\n",
    "\n",
    "    K = kernel_traced_fn(X, params)\n",
    "    vmax = np.percentile(K, 99.5)\n",
    "    im = ax2.imshow(K, cmap=\"Blues\", vmin=0, vmax=vmax)\n",
    "    # cbar = plt.colorbar(im, ax=ax2)\n",
    "    ax2.set(xticks=[], yticks=[], xlabel=f\"Step {t}\")\n",
    "    for spine in ax2.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"logs/plots/mnist-representations-blue.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithmic representations and kernel evolution\n",
    "\n",
    "X = np.concatenate([ds_train[\"x\"], ds_test[\"x\"]], axis=0)\n",
    "Y = np.concatenate([ds_train[\"y\"], ds_test[\"y\"]], axis=0)\n",
    "# print(jnp.unique(Y, return_counts=True))\n",
    "\n",
    "# filter_ = X[:, 0] == 24\n",
    "# filter_ = (1 <= Y) & (Y <= 46 - 1)\n",
    "filter_ = (5 <= Y) & (Y <= 46 - 5)\n",
    "# filter_ = (10 <= Y) & (Y <= 46 - 10)\n",
    "# filter_ = slice(None)\n",
    "# filter_ = (14 <= Y) & (Y <= 33)\n",
    "X, Y = X[filter_], Y[filter_]\n",
    "\n",
    "# X, _, Y, _ = train_test_split(xs, ys, train_size=len(xs), stratify=ys)\n",
    "\n",
    "ts = range(0, 50000 + 1, 10000)\n",
    "\n",
    "fig, axs = plt.subplots(1, len(ts), figsize=(2 * len(ts), 2), squeeze=False)\n",
    "\n",
    "for ax, t in zip(axs[0], ts):\n",
    "    params = get_params(t)\n",
    "    E = params[\"params\"][\"Embed_0\"][\"embedding\"]\n",
    "    E = E[X].reshape(len(X), -1)\n",
    "    pca = PCA(n_components=2)\n",
    "    E = pca.fit_transform(E)\n",
    "    v1, v2 = pca.explained_variance_ratio_\n",
    "\n",
    "    ax.scatter(x=E[:, 0], y=E[:, 1], c=Y, cmap=\"tab10\", alpha=0.6, s=1)\n",
    "    ax.set(xticks=[], yticks=[], aspect=1 / ax.get_data_ratio(), title=f\"Step {t}\")\n",
    "    ax.set_xlabel(f\"PCA 1: {v1*100:.2f}\\%\", fontsize=\"small\")\n",
    "    ax.set_ylabel(f\"PCA 2: {v2*100:.2f}\\%\", fontsize=\"small\")\n",
    "\n",
    "# fig.savefig(\n",
    "#     \"logs/plots/algorithmic-representations-mlp-1.jpg\",\n",
    "#     bbox_inches=\"tight\",\n",
    "#     dpi=300,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "samples = ds_test.shuffle().select(range(n))\n",
    "xs, ys = samples[\"x\"], samples[\"y\"]\n",
    "ys_pred = jnp.argmax(state.apply_fn(state.params, xs), axis=-1)\n",
    "\n",
    "# plot the confusion matrix\n",
    "confusion_matrix = pd.crosstab(ys, ys_pred, rownames=[\"True\"], colnames=[\"Predicted\"])\n",
    "# remove the diagonal\n",
    "confusion_matrix.values[np.arange(10), np.arange(10)] = 0\n",
    "sns.heatmap(confusion_matrix, annot=True, square=True, fmt=\"d\", cmap=\"RdBu\", center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_flat = rearrange(K, \"b1 b2 d1 d2 -> (b1 d1) (b2 d2)\")\n",
    "lambda_, es = jnp.linalg.eigh(K_flat)\n",
    "print(jnp.linalg.matrix_rank(K_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(10, 8))\n",
    "# sns.lineplot(lambda_[::-1], ax=ax)\n",
    "# ax.set(yscale=\"log\")\n",
    "\n",
    "for eig_idx in range(1, 10):\n",
    "    ax = axs.flatten()[eig_idx - 1]\n",
    "    e = rearrange(es[:, -eig_idx], \"(b d) -> b d\", d=10)\n",
    "    sns.heatmap(e, ax=ax, cmap=\"RdBu\", center=0)\n",
    "    ax.set(\n",
    "        yticks=[],\n",
    "        ylabel=\"Sample (sorted)\",\n",
    "        xlabel=\"Class\",\n",
    "        title=f\"Eigenvector {eig_idx} (λ={lambda_[-eig_idx]:.1e})\",\n",
    "    )\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# eig_idx = -1\n",
    "# e = rearrange(es[:, eig_idx], \"(b d) -> b d\", d=10)\n",
    "\n",
    "# print(lambda_[-1])\n",
    "# sns.heatmap(e, ax=ax, cmap=\"RdBu\", center=0)\n",
    "# ax.set(yticks=[], ylabel=\"Sample (sorted)\", xlabel=\"Class\")\n",
    "\n",
    "# e_max_idx = jnp.argmax(jnp.abs(e), axis=1)\n",
    "# e_max = jnp.abs(e)[jnp.arange(e.shape[0]), e_max_idx]\n",
    "# e_max_sign = e[jnp.arange(e.shape[0]), e_max_idx]\n",
    "# top_samples = jnp.argsort(e_max)[-20:]\n",
    "\n",
    "# img = x[top_samples] * rearrange(e_max_sign[top_samples], \"b -> b 1 1\")\n",
    "# img = rearrange(img[::-1], \"b h w -> h (b w)\")\n",
    "# v = jnp.max(jnp.abs(img))\n",
    "# ax.imshow(img, aspect=\"equal\", cmap=\"RdBu\", vmin=-v, vmax=v)\n",
    "# ax.set(xticks=[], yticks=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idiots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
