{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import neural_tangents as nt\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from einops import rearrange\n",
    "\n",
    "from idiots.experiments.compute_results.compute_results import restore_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = Path(\"logs/checkpoints/mnist/mnist_grokking_slower/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/mnist/mnist_gd_grokking/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/grokking/division_47/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/gradient_flow/exp37/checkpoints\")\n",
    "# checkpoint_dir = Path(\"logs/checkpoints/grokking/exp112/checkpoints\")\n",
    "checkpoint_dir = Path(\"logs/checkpoints/grokking/exp123/checkpoints\")\n",
    "\n",
    "config, apply_fn, get_params, ds_train, ds_test, all_steps = restore_checkpoint(\n",
    "    checkpoint_dir,\n",
    "    # experiment_type=\"gradient_flow_\",\n",
    "    # experiment_type=\"mnist\",\n",
    "    experiment_type=\"algorithmic\",\n",
    ")\n",
    "n_classes = ds_train.features[\"y\"].num_classes\n",
    "\n",
    "\n",
    "def kernel_fn(x, params):\n",
    "    k = nt.batch(\n",
    "        nt.empirical_ntk_fn(\n",
    "            apply_fn,\n",
    "            vmap_axes=0,\n",
    "            trace_axes=(-1,),\n",
    "            implementation=nt.NtkImplementation.STRUCTURED_DERIVATIVES,\n",
    "        ),\n",
    "        batch_size=64,\n",
    "    )(x, None, params)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "samples = ds_test.shuffle().select(range(128))\n",
    "x, y = samples[\"x\"], samples[\"y\"]\n",
    "order_ = np.argsort(y)\n",
    "x, y = x[order_], y[order_]\n",
    "\n",
    "K = kernel_fn(x, get_params(all_steps[-1]))\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic\n",
    "x = jnp.concat([ds_train[\"x\"], ds_test[\"x\"]], axis=0)\n",
    "y = jnp.concat([ds_train[\"y\"], ds_test[\"y\"]], axis=0)\n",
    "order_ = np.lexsort((x[:, 2], x[:, 0], y))\n",
    "x = x[order_]\n",
    "y = y[order_]\n",
    "\n",
    "indices = np.arange(2048)\n",
    "# indices = np.random.choice(len(x), 256, replace=False)\n",
    "# [indices] = np.where(np.isin(x[:0], np.arange(1)))\n",
    "# indices = indices[:256]\n",
    "# indices = np.arange(2048)\n",
    "x, y = x[indices], y[indices]\n",
    "\n",
    "K = kernel_fn(x, get_params(16000))\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_order = np.ar\n",
    "# K_reduced = K[new_order][:, new_order]\n",
    "K_reduced = K\n",
    "# K_reduced = jnp.mean(K, axis=(-2, -1))\n",
    "# K_reduced = jnp.mean(K, axis=(0, 1))\n",
    "# K_reduced = K[0, 0]\n",
    "print(f\"{K_reduced.shape=}\")\n",
    "# y_pred = jnp.argmax(apply_fn(params, x), axis=-1)\n",
    "# print(f\"{y_pred=}\")\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(10, 6), gridspec_kw={\"height_ratios\": [1, 10]})\n",
    "# axs[0].imshow(rearrange(x, \"b h w -> h (b w)\"), aspect=\"equal\", cmap=\"gray\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "# labels = x[:, [0, 2]].tolist()\n",
    "sns.heatmap(\n",
    "    K_reduced,\n",
    "    ax=ax,\n",
    "    square=True,\n",
    "    cmap=\"RdBu\",\n",
    "    # center=0,\n",
    "    # xticklabels=[],\n",
    "    # yticklabels=[],\n",
    "    cbar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "samples = ds_test.shuffle().select(range(n))\n",
    "xs, ys = samples[\"x\"], samples[\"y\"]\n",
    "ys_pred = jnp.argmax(state.apply_fn(state.params, xs), axis=-1)\n",
    "\n",
    "# plot the confusion matrix\n",
    "confusion_matrix = pd.crosstab(ys, ys_pred, rownames=[\"True\"], colnames=[\"Predicted\"])\n",
    "# remove the diagonal\n",
    "confusion_matrix.values[np.arange(10), np.arange(10)] = 0\n",
    "sns.heatmap(confusion_matrix, annot=True, square=True, fmt=\"d\", cmap=\"RdBu\", center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_flat = rearrange(K, \"b1 b2 d1 d2 -> (b1 d1) (b2 d2)\")\n",
    "lambda_, es = jnp.linalg.eigh(K_flat)\n",
    "print(jnp.linalg.matrix_rank(K_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(10, 8))\n",
    "# sns.lineplot(lambda_[::-1], ax=ax)\n",
    "# ax.set(yscale=\"log\")\n",
    "\n",
    "for eig_idx in range(1, 10):\n",
    "    ax = axs.flatten()[eig_idx - 1]\n",
    "    e = rearrange(es[:, -eig_idx], \"(b d) -> b d\", d=10)\n",
    "    sns.heatmap(e, ax=ax, cmap=\"RdBu\", center=0)\n",
    "    ax.set(\n",
    "        yticks=[],\n",
    "        ylabel=\"Sample (sorted)\",\n",
    "        xlabel=\"Class\",\n",
    "        title=f\"Eigenvector {eig_idx} (Î»={lambda_[-eig_idx]:.1e})\",\n",
    "    )\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# eig_idx = -1\n",
    "# e = rearrange(es[:, eig_idx], \"(b d) -> b d\", d=10)\n",
    "\n",
    "# print(lambda_[-1])\n",
    "# sns.heatmap(e, ax=ax, cmap=\"RdBu\", center=0)\n",
    "# ax.set(yticks=[], ylabel=\"Sample (sorted)\", xlabel=\"Class\")\n",
    "\n",
    "# e_max_idx = jnp.argmax(jnp.abs(e), axis=1)\n",
    "# e_max = jnp.abs(e)[jnp.arange(e.shape[0]), e_max_idx]\n",
    "# e_max_sign = e[jnp.arange(e.shape[0]), e_max_idx]\n",
    "# top_samples = jnp.argsort(e_max)[-20:]\n",
    "\n",
    "# img = x[top_samples] * rearrange(e_max_sign[top_samples], \"b -> b 1 1\")\n",
    "# img = rearrange(img[::-1], \"b h w -> h (b w)\")\n",
    "# v = jnp.max(jnp.abs(img))\n",
    "# ax.imshow(img, aspect=\"equal\", cmap=\"RdBu\", vmin=-v, vmax=v)\n",
    "# ax.set(xticks=[], yticks=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idiots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
