{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import neural_tangents as nt\n",
    "import numpy as np\n",
    "import optax\n",
    "import orbax.checkpoint as ocp\n",
    "from einops import rearrange\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "    RBF,\n",
    "    Kernel,\n",
    "    NormalizedKernelMixin,\n",
    "    StationaryKernelMixin,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from idiots.dataset.dataloader import DataLoader\n",
    "from idiots.experiments.classification.training import restore as mnist_restore, init_state_and_ds\n",
    "from idiots.experiments.classification.config import get_config\n",
    "from idiots.experiments.grokking.training import TrainState, eval_step\n",
    "from idiots.experiments.grokking.training import restore as algorithmic_restore\n",
    "from idiots.utils import metrics\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_checkpoint(state, config, train_loader, test_loader, scale_training_data=False):\n",
    "    \"\"\"Compute training/test accuracy/loss for each timestep\"\"\"\n",
    "\n",
    "    def eval_loss_acc(loader):\n",
    "        for batch in loader:\n",
    "          current_batch = batch.copy() \n",
    "          if scale_training_data:\n",
    "            current_batch[\"x\"] = current_batch[\"x\"]\n",
    "          logs = eval_step(state, current_batch, config.loss_variant)\n",
    "          metrics.log(**logs)\n",
    "        \n",
    "        [losses, accuracies] = metrics.collect(\"eval_loss\", \"eval_accuracy\")\n",
    "        loss = jnp.concatenate(losses).mean().item()\n",
    "        acc = jnp.concatenate(accuracies).mean().item()\n",
    "        return loss, acc\n",
    "\n",
    "    train_loss, train_acc = eval_loss_acc(train_loader)\n",
    "    test_loss, test_acc = eval_loss_acc(test_loader)\n",
    "\n",
    "    return train_loss, train_acc, test_loss, test_acc\n",
    "\n",
    "\n",
    "def generate_analysis_dataset(\n",
    "    X_test,\n",
    "    Y_test,\n",
    "    num_analysis_training_samples,\n",
    "    num_analysis_test_samples,\n",
    "    experiment_type,\n",
    "):\n",
    "    analysis_X_train, X_test, analysis_Y_train, Y_test = train_test_split(\n",
    "        X_test, Y_test, train_size=num_analysis_training_samples, stratify=Y_test\n",
    "    )\n",
    "    analysis_X_test, X_test, analysis_Y_test, Y_test = train_test_split(\n",
    "        X_test, Y_test, train_size=num_analysis_test_samples, stratify=Y_test\n",
    "    )\n",
    "\n",
    "    if experiment_type == \"mnist\":\n",
    "        analysis_X_train = rearrange(analysis_X_train, \"b h w -> b (h w)\")\n",
    "        analysis_X_test = rearrange(analysis_X_test, \"b h w -> b (h w)\")\n",
    "\n",
    "    return (analysis_X_train, analysis_Y_train, analysis_X_test, analysis_Y_test)\n",
    "\n",
    "\n",
    "# Return a batched kernel function where trace_axes=() [for calculating DOTS]\n",
    "def compute_kernel_trace_axes_fn(model_state_apply_fn, batch_size):\n",
    "    kernel_fn_trace_axes = nt.empirical_ntk_fn(\n",
    "        model_state_apply_fn,\n",
    "        vmap_axes=0,\n",
    "        trace_axes=(),\n",
    "        implementation=nt.NtkImplementation.STRUCTURED_DERIVATIVES,\n",
    "    )\n",
    "    return nt.batch(kernel_fn_trace_axes, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Return a batched kernel function where trace_axes is not defined [for computing everything other than DOTS]\n",
    "def compute_kernel_fn(model_state_apply_fn, batch_size):\n",
    "    kernel_fn = nt.empirical_ntk_fn(\n",
    "        model_state_apply_fn,\n",
    "        vmap_axes=0,\n",
    "        implementation=nt.NtkImplementation.STRUCTURED_DERIVATIVES,\n",
    "    )\n",
    "    return nt.batch(kernel_fn, batch_size=batch_size)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def compute_dots(kernel_trace_axes):\n",
    "    \"\"\"Compute DOTS on the kernel_trace_axes matrix\"\"\"\n",
    "    ntk_flat = rearrange(kernel_trace_axes, \"b1 b2 d1 d2 -> (b1 d1) (b2 d2)\")\n",
    "    S = jnp.linalg.svd(ntk_flat, full_matrices=False, compute_uv=False)\n",
    "    m, n = ntk_flat.shape\n",
    "\n",
    "    tol_1 = S.max(-1) * np.max([m, n]).astype(S.dtype) * jnp.finfo(S.dtype).eps\n",
    "    tol_2 = 0.5 * S.max(-1) * jnp.finfo(S.dtype).eps * jnp.sqrt(m + n + 1)\n",
    "    dots_1 = jnp.sum(S > tol_1)\n",
    "    dots_2 = jnp.sum(S > tol_2)\n",
    "\n",
    "    s_dist = S / jnp.sum(S)\n",
    "    dots_3 = jnp.exp(-jnp.sum(s_dist * jnp.log(s_dist)))\n",
    "\n",
    "    return dots_1, dots_2, dots_3\n",
    "\n",
    "\n",
    "# Given the a custom kernel and training/test data, compute the accuracy of an SVM\n",
    "def compute_svm_accuracy(\n",
    "    custom_kernel_fn,\n",
    "    analysis_X_train,\n",
    "    analysis_Y_train,\n",
    "    analysis_X_test,\n",
    "    analysis_Y_test,\n",
    "):\n",
    "    svc = SVC(kernel=custom_kernel_fn)\n",
    "    svc.fit(analysis_X_train, analysis_Y_train)\n",
    "\n",
    "    train_accuracy = svc.score(analysis_X_train, analysis_Y_train)\n",
    "    test_accuracy = svc.score(analysis_X_test, analysis_Y_test)\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "\n",
    "# Given the a custom kernel and training/test data, compute the accuracy of a Gaussian Process\n",
    "def compute_gp_accuracy(\n",
    "    custom_kernel_fn,\n",
    "    analysis_X_train,\n",
    "    analysis_Y_train,\n",
    "    analysis_X_test,\n",
    "    analysis_Y_test,\n",
    "    num_y_classes,\n",
    "):\n",
    "    analysis_Y_train_one_hot = jax.nn.one_hot(analysis_Y_train, num_y_classes)\n",
    "\n",
    "    class CustomKernel(StationaryKernelMixin, NormalizedKernelMixin, Kernel):\n",
    "        \"\"\"GP kernel object (for compatability with sklearn.gaussian_proccess)\"\"\"\n",
    "\n",
    "        def __init__(self) -> None:\n",
    "            super().__init__()\n",
    "\n",
    "        def __call__(self, X, Y=None, eval_gradient=False):\n",
    "            kernel = np.array(custom_kernel_fn(X, Y))\n",
    "\n",
    "            if eval_gradient:\n",
    "                return kernel, np.zeros(X.shape)\n",
    "            else:\n",
    "                return kernel\n",
    "\n",
    "    custom_gp_kernel = CustomKernel()  # RBF(length_scale=1e3)\n",
    "    gaussian_process_classifier = GaussianProcessRegressor(kernel=custom_gp_kernel)\n",
    "    gaussian_process_classifier.fit(analysis_X_train, analysis_Y_train_one_hot)\n",
    "\n",
    "    predictions = gaussian_process_classifier.predict(analysis_X_test).argmax(axis=-1)\n",
    "    accuracy = accuracy_score(analysis_Y_test, predictions)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def compute_kernel_alignment(kernel, analysis_Y_test):\n",
    "    \"\"\"Compute the kernel alignment metric.\n",
    "\n",
    "    Source: Shan 2022: A Theory of Neural Tangent Kernel Alignment and Its Influence on Training\n",
    "    We use the \"traced\" kernel here.\n",
    "    \"\"\"\n",
    "    Y = jax.nn.one_hot(analysis_Y_test, kernel.shape[-1])\n",
    "    YYT = Y @ Y.T\n",
    "    K = jnp.trace(kernel, axis1=-2, axis2=-1) / kernel.shape[-1]\n",
    "    kernel_alignment = jnp.sum(YYT * K) / (jnp.linalg.norm(K) * jnp.linalg.norm(YYT))\n",
    "    return kernel_alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "logs_base_path: e.g. \"/home/dm894/idiots/logs/\"\n",
    "experiments: (\n",
    "    experiment_json_file_name: e.g. \"mnist-100\" to save file as \"mnist-100.json\",\n",
    "    experiment_checkpoint_path: e.g. \"checkpoints/mnist-100/checkpoints\",\n",
    "    experiment_type: either \"algorithmic\" for modular division or S5, or \"mnist\" for mnist,\n",
    "    step_distance: distance between checkpoints you want to analyse,\n",
    "    total_steps: value of the highest checkpoint you want to analyse,\n",
    "    kernel_samples: number of samples used to compute the DOTS and kernel alignment,\n",
    "    num_analysis_training_samples: number of training samples used in the remaining analysis: when fitting the SVM and GP,\n",
    "    num_analysis_test_samples: number of test samples used in the remaining analysis: when fitting the SVM and GP,\n",
    "    scale_training_data: reverse MNIST pixel values during testing \n",
    ")\n",
    "add_kernel: whether the kernel should be computed and added to the log file (can take up a large amount of space)\n",
    "kernel_batch_size: batch size when computing the kernels using nt.batch\n",
    "\"\"\"\n",
    "\n",
    "logs_base_path = \"/home/dm894/idiots/logs/\"\n",
    "\n",
    "experiment = (\n",
    "        \"mnist-grokking-train-scaled\",\n",
    "        \"checkpoints/mnist/exp12/checkpoints\",\n",
    "        \"mnist\",\n",
    "        1000,\n",
    "        200_000,\n",
    "        256,\n",
    "        64,\n",
    "        256,\n",
    "        True\n",
    "    )\n",
    "\n",
    "add_kernel = False\n",
    "kernel_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Given directory is read only=/home/dm894/idiots/logs/checkpoints/mnist/exp10/checkpoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: mnist-grokking-train-scaled\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    experiment_json_file_name,\n",
    "    experiment_checkpoint_path,\n",
    "    experiment_type,\n",
    "    step_distance,\n",
    "    total_steps,\n",
    "    kernel_samples,\n",
    "    num_analysis_training_samples,\n",
    "    num_analysis_test_samples,\n",
    "    scale_training_data,\n",
    ") = experiment\n",
    "\n",
    "\n",
    "print(f\"Experiment: {experiment_json_file_name}\")\n",
    "\n",
    "experiment_checkpoint_path = Path(logs_base_path, experiment_checkpoint_path)\n",
    "\n",
    "if experiment_type == \"algorithmic\":\n",
    "    restore_fn = algorithmic_restore\n",
    "elif experiment_type == \"mnist\":\n",
    "    restore_fn = mnist_restore\n",
    "else:\n",
    "    raise ValueError(f\"Experiment type {experiment_type} not valid.\")\n",
    "\n",
    "restore_manager, config, state, ds_train, ds_test = restore_fn(\n",
    "    experiment_checkpoint_path, 0\n",
    ")\n",
    "\n",
    "if len(ds_train) > len(ds_test):\n",
    "    ds_train = ds_train.select(range(len(ds_test)))\n",
    "\n",
    "initial_state, _, _ = init_state_and_ds(config)\n",
    "initial_params = initial_state.params\n",
    "initial_weight_norm = optax.global_norm(initial_params).item()\n",
    "\n",
    "train_loader = DataLoader(ds_train, config.train_batch_size)\n",
    "test_loader = DataLoader(ds_test, config.test_batch_size)\n",
    "kernel_fn = compute_kernel_fn(state.apply_fn, kernel_batch_size)\n",
    "kernel_trace_axes_fn = compute_kernel_trace_axes_fn(\n",
    "    state.apply_fn, kernel_batch_size\n",
    ")\n",
    "\n",
    "X_test, Y_test = jnp.array(ds_test[\"x\"]), jnp.array(ds_test[\"y\"])\n",
    "\n",
    "if scale_training_data: \n",
    "  X_test = X_test // 10\n",
    "\n",
    "# kernel dataset is used for computing the kernels used in DOTS and kernel alignment\n",
    "# analysis datasets are used for the remaining analysis: SVM, GP\n",
    "(\n",
    "    analysis_X_train,\n",
    "    analysis_Y_train,\n",
    "    analysis_X_test,\n",
    "    analysis_Y_test,\n",
    ") = generate_analysis_dataset(\n",
    "    X_test,\n",
    "    Y_test,\n",
    "    num_analysis_training_samples,\n",
    "    num_analysis_test_samples,\n",
    "    experiment_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"step\": 0,\n",
      "  \"train_loss\": 79.2480239868164,\n",
      "  \"test_loss\": 78.21125793457031,\n",
      "  \"training_acc\": 0.13984374701976776,\n",
      "  \"test_acc\": 0.1297999918460846,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.73828125,\n",
      "  \"gp_accuracy\": 0.7421875,\n",
      "  \"dots\": 2530,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 422.560791015625,\n",
      "  \"kernel_alignment\": 0.39446383714675903,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 182.88633728027344,\n",
      "  \"relative_weight_norm\": 1.0\n",
      "}\n",
      "{\n",
      "  \"step\": 100,\n",
      "  \"train_loss\": 3.0947136878967285,\n",
      "  \"test_loss\": 4.1706390380859375,\n",
      "  \"training_acc\": 0.17031250894069672,\n",
      "  \"test_acc\": 0.15600000321865082,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.69921875,\n",
      "  \"gp_accuracy\": 0.71875,\n",
      "  \"dots\": 2557,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 604.6482543945312,\n",
      "  \"kernel_alignment\": 0.4181216359138489,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 182.4588165283203,\n",
      "  \"relative_weight_norm\": 0.9976623691068953\n",
      "}\n",
      "{\n",
      "  \"step\": 200,\n",
      "  \"train_loss\": 1.2411956787109375,\n",
      "  \"test_loss\": 2.425511360168457,\n",
      "  \"training_acc\": 0.2601562440395355,\n",
      "  \"test_acc\": 0.1876000016927719,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.70703125,\n",
      "  \"gp_accuracy\": 0.72265625,\n",
      "  \"dots\": 2558,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 682.262451171875,\n",
      "  \"kernel_alignment\": 0.42720115184783936,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 182.0672607421875,\n",
      "  \"relative_weight_norm\": 0.9955213902237503\n",
      "}\n",
      "{\n",
      "  \"step\": 300,\n",
      "  \"train_loss\": 0.5303566455841064,\n",
      "  \"test_loss\": 1.7302007675170898,\n",
      "  \"training_acc\": 0.38359376788139343,\n",
      "  \"test_acc\": 0.20499999821186066,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6953125,\n",
      "  \"gp_accuracy\": 0.71875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 745.634765625,\n",
      "  \"kernel_alignment\": 0.4325181841850281,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 181.7198028564453,\n",
      "  \"relative_weight_norm\": 0.9936215332365675\n",
      "}\n",
      "{\n",
      "  \"step\": 400,\n",
      "  \"train_loss\": 0.22212930023670197,\n",
      "  \"test_loss\": 1.4063001871109009,\n",
      "  \"training_acc\": 0.6343750357627869,\n",
      "  \"test_acc\": 0.2345999926328659,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.68359375,\n",
      "  \"gp_accuracy\": 0.7109375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 782.8693237304688,\n",
      "  \"kernel_alignment\": 0.43326687812805176,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 181.4180908203125,\n",
      "  \"relative_weight_norm\": 0.9919718089290025\n",
      "}\n",
      "{\n",
      "  \"step\": 500,\n",
      "  \"train_loss\": 0.08663655817508698,\n",
      "  \"test_loss\": 1.2357091903686523,\n",
      "  \"training_acc\": 0.8929687738418579,\n",
      "  \"test_acc\": 0.2533999979496002,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66796875,\n",
      "  \"gp_accuracy\": 0.6953125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 801.0960083007812,\n",
      "  \"kernel_alignment\": 0.43366509675979614,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 181.17474365234375,\n",
      "  \"relative_weight_norm\": 0.990641216542564\n",
      "}\n",
      "{\n",
      "  \"step\": 600,\n",
      "  \"train_loss\": 0.03211245685815811,\n",
      "  \"test_loss\": 1.1458970308303833,\n",
      "  \"training_acc\": 0.9859375357627869,\n",
      "  \"test_acc\": 0.2680000066757202,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6796875,\n",
      "  \"gp_accuracy\": 0.6953125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 811.6478881835938,\n",
      "  \"kernel_alignment\": 0.43284133076667786,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 180.99325561523438,\n",
      "  \"relative_weight_norm\": 0.9896488622759287\n",
      "}\n",
      "{\n",
      "  \"step\": 700,\n",
      "  \"train_loss\": 0.012517176568508148,\n",
      "  \"test_loss\": 1.0923757553100586,\n",
      "  \"training_acc\": 0.999218761920929,\n",
      "  \"test_acc\": 0.28039997816085815,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.67578125,\n",
      "  \"gp_accuracy\": 0.703125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 817.5040893554688,\n",
      "  \"kernel_alignment\": 0.43358132243156433,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 180.8512420654297,\n",
      "  \"relative_weight_norm\": 0.9888723496511116\n",
      "}\n",
      "{\n",
      "  \"step\": 800,\n",
      "  \"train_loss\": 0.007030968554317951,\n",
      "  \"test_loss\": 1.063494086265564,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.28380000591278076,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66796875,\n",
      "  \"gp_accuracy\": 0.72265625,\n",
      "  \"dots\": 2559,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 820.319580078125,\n",
      "  \"kernel_alignment\": 0.43320387601852417,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 180.69943237304688,\n",
      "  \"relative_weight_norm\": 0.9880422729234545\n",
      "}\n",
      "{\n",
      "  \"step\": 900,\n",
      "  \"train_loss\": 0.005345768760889769,\n",
      "  \"test_loss\": 1.0339336395263672,\n",
      "  \"training_acc\": 0.999218761920929,\n",
      "  \"test_acc\": 0.28919997811317444,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6875,\n",
      "  \"gp_accuracy\": 0.69921875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 821.3203125,\n",
      "  \"kernel_alignment\": 0.43282490968704224,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 180.5244140625,\n",
      "  \"relative_weight_norm\": 0.9870852943259846\n",
      "}\n",
      "{\n",
      "  \"step\": 1000,\n",
      "  \"train_loss\": 0.0039058809634298086,\n",
      "  \"test_loss\": 1.0088353157043457,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.28859999775886536,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.67578125,\n",
      "  \"gp_accuracy\": 0.73046875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 820.8250122070312,\n",
      "  \"kernel_alignment\": 0.4327772855758667,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 180.3300323486328,\n",
      "  \"relative_weight_norm\": 0.9860224390205645\n",
      "}\n",
      "{\n",
      "  \"step\": 1100,\n",
      "  \"train_loss\": 0.004469980485737324,\n",
      "  \"test_loss\": 0.9867005348205566,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.2935999929904938,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6875,\n",
      "  \"gp_accuracy\": 0.734375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 821.9169921875,\n",
      "  \"kernel_alignment\": 0.43246251344680786,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 180.1293182373047,\n",
      "  \"relative_weight_norm\": 0.984924958944617\n",
      "}\n",
      "{\n",
      "  \"step\": 1200,\n",
      "  \"train_loss\": 0.004160101991146803,\n",
      "  \"test_loss\": 0.964002788066864,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.29580000042915344,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.671875,\n",
      "  \"gp_accuracy\": 0.71875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 822.2592163085938,\n",
      "  \"kernel_alignment\": 0.4323260188102722,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 179.91946411132812,\n",
      "  \"relative_weight_norm\": 0.983777502392655\n",
      "}\n",
      "{\n",
      "  \"step\": 1300,\n",
      "  \"train_loss\": 0.003799679921939969,\n",
      "  \"test_loss\": 0.9396880865097046,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.29739999771118164,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6875,\n",
      "  \"gp_accuracy\": 0.73828125,\n",
      "  \"dots\": 2559,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 823.691162109375,\n",
      "  \"kernel_alignment\": 0.4321981966495514,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 179.71148681640625,\n",
      "  \"relative_weight_norm\": 0.9826403081220785\n",
      "}\n",
      "{\n",
      "  \"step\": 1400,\n",
      "  \"train_loss\": 0.0046405489556491375,\n",
      "  \"test_loss\": 0.9190204739570618,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.30300000309944153,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6796875,\n",
      "  \"gp_accuracy\": 0.7265625,\n",
      "  \"dots\": 2559,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 823.6927490234375,\n",
      "  \"kernel_alignment\": 0.4324532449245453,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 179.4999542236328,\n",
      "  \"relative_weight_norm\": 0.9814836739200972\n",
      "}\n",
      "{\n",
      "  \"step\": 1500,\n",
      "  \"train_loss\": 0.003328222082927823,\n",
      "  \"test_loss\": 0.9037206768989563,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3001999855041504,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6953125,\n",
      "  \"gp_accuracy\": 0.73828125,\n",
      "  \"dots\": 2559,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 822.9797973632812,\n",
      "  \"kernel_alignment\": 0.43221592903137207,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 179.28590393066406,\n",
      "  \"relative_weight_norm\": 0.980313273243087\n",
      "}\n",
      "{\n",
      "  \"step\": 1600,\n",
      "  \"train_loss\": 0.003281580051407218,\n",
      "  \"test_loss\": 0.8852941393852234,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.30539998412132263,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.69140625,\n",
      "  \"gp_accuracy\": 0.7265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 824.9769287109375,\n",
      "  \"kernel_alignment\": 0.43217313289642334,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 179.0731964111328,\n",
      "  \"relative_weight_norm\": 0.9791502146860922\n",
      "}\n",
      "{\n",
      "  \"step\": 1700,\n",
      "  \"train_loss\": 0.003433517413213849,\n",
      "  \"test_loss\": 0.866913914680481,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3093999922275543,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66796875,\n",
      "  \"gp_accuracy\": 0.7265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 825.2566528320312,\n",
      "  \"kernel_alignment\": 0.4320238530635834,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 178.8541717529297,\n",
      "  \"relative_weight_norm\": 0.977952614791752\n",
      "}\n",
      "{\n",
      "  \"step\": 1800,\n",
      "  \"train_loss\": 0.003152173710986972,\n",
      "  \"test_loss\": 0.849958062171936,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3077999949455261,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66796875,\n",
      "  \"gp_accuracy\": 0.73828125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 825.9971923828125,\n",
      "  \"kernel_alignment\": 0.4317569434642792,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 178.63966369628906,\n",
      "  \"relative_weight_norm\": 0.976779711119282\n",
      "}\n",
      "{\n",
      "  \"step\": 1900,\n",
      "  \"train_loss\": 0.0030028782784938812,\n",
      "  \"test_loss\": 0.8316383361816406,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3109999895095825,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.671875,\n",
      "  \"gp_accuracy\": 0.7265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 828.1998901367188,\n",
      "  \"kernel_alignment\": 0.4314572811126709,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 178.42274475097656,\n",
      "  \"relative_weight_norm\": 0.9755936250040569\n",
      "}\n",
      "{\n",
      "  \"step\": 2000,\n",
      "  \"train_loss\": 0.003372054547071457,\n",
      "  \"test_loss\": 0.8130078911781311,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.31619998812675476,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6953125,\n",
      "  \"gp_accuracy\": 0.7265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 826.5294799804688,\n",
      "  \"kernel_alignment\": 0.43197354674339294,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 178.2009735107422,\n",
      "  \"relative_weight_norm\": 0.9743810071369579\n",
      "}\n",
      "{\n",
      "  \"step\": 2100,\n",
      "  \"train_loss\": 0.004438153002411127,\n",
      "  \"test_loss\": 0.7986069917678833,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3190000057220459,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66796875,\n",
      "  \"gp_accuracy\": 0.73046875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 827.1370239257812,\n",
      "  \"kernel_alignment\": 0.43209603428840637,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 177.98231506347656,\n",
      "  \"relative_weight_norm\": 0.9731854096389855\n",
      "}\n",
      "{\n",
      "  \"step\": 2200,\n",
      "  \"train_loss\": 0.0027890282217413187,\n",
      "  \"test_loss\": 0.7811335921287537,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.323199987411499,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.671875,\n",
      "  \"gp_accuracy\": 0.73046875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 829.7383422851562,\n",
      "  \"kernel_alignment\": 0.43185386061668396,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 177.7646484375,\n",
      "  \"relative_weight_norm\": 0.9719952352978427\n",
      "}\n",
      "{\n",
      "  \"step\": 2300,\n",
      "  \"train_loss\": 0.002804151503369212,\n",
      "  \"test_loss\": 0.7641043066978455,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.323199987411499,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66796875,\n",
      "  \"gp_accuracy\": 0.71484375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 832.4402465820312,\n",
      "  \"kernel_alignment\": 0.43225768208503723,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 177.547119140625,\n",
      "  \"relative_weight_norm\": 0.9708058118553379\n",
      "}\n",
      "{\n",
      "  \"step\": 2400,\n",
      "  \"train_loss\": 0.002815241925418377,\n",
      "  \"test_loss\": 0.748575747013092,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.32819998264312744,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6796875,\n",
      "  \"gp_accuracy\": 0.7265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 830.552978515625,\n",
      "  \"kernel_alignment\": 0.43186286091804504,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 177.32794189453125,\n",
      "  \"relative_weight_norm\": 0.9696073776291777\n",
      "}\n",
      "{\n",
      "  \"step\": 2500,\n",
      "  \"train_loss\": 0.0033495165407657623,\n",
      "  \"test_loss\": 0.7339190244674683,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.33059999346733093,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.671875,\n",
      "  \"gp_accuracy\": 0.73046875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 830.0421752929688,\n",
      "  \"kernel_alignment\": 0.43159469962120056,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 177.1089630126953,\n",
      "  \"relative_weight_norm\": 0.9684100280343835\n",
      "}\n",
      "{\n",
      "  \"step\": 2600,\n",
      "  \"train_loss\": 0.002434579422697425,\n",
      "  \"test_loss\": 0.7207747101783752,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.33159998059272766,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65234375,\n",
      "  \"gp_accuracy\": 0.7109375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 832.0922241210938,\n",
      "  \"kernel_alignment\": 0.4309130311012268,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 176.8936004638672,\n",
      "  \"relative_weight_norm\": 0.9672324521037218\n",
      "}\n",
      "{\n",
      "  \"step\": 2700,\n",
      "  \"train_loss\": 0.0027633989229798317,\n",
      "  \"test_loss\": 0.706155002117157,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3351999819278717,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66015625,\n",
      "  \"gp_accuracy\": 0.70703125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 831.3359375,\n",
      "  \"kernel_alignment\": 0.4309042692184448,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 176.6758270263672,\n",
      "  \"relative_weight_norm\": 0.9660416937303051\n",
      "}\n",
      "{\n",
      "  \"step\": 2800,\n",
      "  \"train_loss\": 0.002229064702987671,\n",
      "  \"test_loss\": 0.6922534704208374,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3346000015735626,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66015625,\n",
      "  \"gp_accuracy\": 0.72265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 831.1654663085938,\n",
      "  \"kernel_alignment\": 0.43088003993034363,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 176.45518493652344,\n",
      "  \"relative_weight_norm\": 0.9648352499186735\n",
      "}\n",
      "{\n",
      "  \"step\": 2900,\n",
      "  \"train_loss\": 0.0027111065573990345,\n",
      "  \"test_loss\": 0.6771652102470398,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.34199997782707214,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65625,\n",
      "  \"gp_accuracy\": 0.703125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 831.37353515625,\n",
      "  \"kernel_alignment\": 0.4307345151901245,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 176.23741149902344,\n",
      "  \"relative_weight_norm\": 0.9636444915452568\n",
      "}\n",
      "{\n",
      "  \"step\": 3000,\n",
      "  \"train_loss\": 0.002656111493706703,\n",
      "  \"test_loss\": 0.6652740836143494,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3449999988079071,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66796875,\n",
      "  \"gp_accuracy\": 0.71875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 830.8112182617188,\n",
      "  \"kernel_alignment\": 0.43008407950401306,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 176.0203857421875,\n",
      "  \"relative_weight_norm\": 0.9624578213977578\n",
      "}\n",
      "{\n",
      "  \"step\": 3100,\n",
      "  \"train_loss\": 0.0027415910735726357,\n",
      "  \"test_loss\": 0.6540957093238831,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.34459999203681946,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65625,\n",
      "  \"gp_accuracy\": 0.71875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 830.3399047851562,\n",
      "  \"kernel_alignment\": 0.4301832616329193,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 175.80056762695312,\n",
      "  \"relative_weight_norm\": 0.9612558829779538\n",
      "}\n",
      "{\n",
      "  \"step\": 3200,\n",
      "  \"train_loss\": 0.0027331269811838865,\n",
      "  \"test_loss\": 0.6417281031608582,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3467999994754791,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.671875,\n",
      "  \"gp_accuracy\": 0.7265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 833.3154907226562,\n",
      "  \"kernel_alignment\": 0.4303637146949768,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 175.58448791503906,\n",
      "  \"relative_weight_norm\": 0.9600743856877385\n",
      "}\n",
      "{\n",
      "  \"step\": 3300,\n",
      "  \"train_loss\": 0.0025098982732743025,\n",
      "  \"test_loss\": 0.6272267699241638,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.34759998321533203,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65234375,\n",
      "  \"gp_accuracy\": 0.7265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 833.1852416992188,\n",
      "  \"kernel_alignment\": 0.4295431077480316,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 175.36654663085938,\n",
      "  \"relative_weight_norm\": 0.9588827095493199\n",
      "}\n",
      "{\n",
      "  \"step\": 3400,\n",
      "  \"train_loss\": 0.002057403791695833,\n",
      "  \"test_loss\": 0.6138015389442444,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.35679998993873596,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6796875,\n",
      "  \"gp_accuracy\": 0.71875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.1141967773438,\n",
      "  \"kernel_alignment\": 0.4297533333301544,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 175.1468963623047,\n",
      "  \"relative_weight_norm\": 0.9576816888945179\n",
      "}\n",
      "{\n",
      "  \"step\": 3500,\n",
      "  \"train_loss\": 0.0024409678298979998,\n",
      "  \"test_loss\": 0.6021755933761597,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.35519999265670776,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6640625,\n",
      "  \"gp_accuracy\": 0.73828125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.3107299804688,\n",
      "  \"kernel_alignment\": 0.42977282404899597,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 174.9271697998047,\n",
      "  \"relative_weight_norm\": 0.956480251073806\n",
      "}\n",
      "{\n",
      "  \"step\": 3600,\n",
      "  \"train_loss\": 0.002380767837166786,\n",
      "  \"test_loss\": 0.5918939113616943,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.35679998993873596,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66796875,\n",
      "  \"gp_accuracy\": 0.73828125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 833.1900024414062,\n",
      "  \"kernel_alignment\": 0.4295663833618164,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 174.71095275878906,\n",
      "  \"relative_weight_norm\": 0.9552980028849526\n",
      "}\n",
      "{\n",
      "  \"step\": 3700,\n",
      "  \"train_loss\": 0.0027951428201049566,\n",
      "  \"test_loss\": 0.5831776261329651,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3635999858379364,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.68359375,\n",
      "  \"gp_accuracy\": 0.71484375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.5736694335938,\n",
      "  \"kernel_alignment\": 0.42958882451057434,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 174.49710083007812,\n",
      "  \"relative_weight_norm\": 0.9541286868393083\n",
      "}\n",
      "{\n",
      "  \"step\": 3800,\n",
      "  \"train_loss\": 0.002031131414696574,\n",
      "  \"test_loss\": 0.5710392594337463,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.36319997906684875,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65234375,\n",
      "  \"gp_accuracy\": 0.73046875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.4769897460938,\n",
      "  \"kernel_alignment\": 0.429377019405365,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 174.28074645996094,\n",
      "  \"relative_weight_norm\": 0.952945687751817\n",
      "}\n",
      "{\n",
      "  \"step\": 3900,\n",
      "  \"train_loss\": 0.0022488811518996954,\n",
      "  \"test_loss\": 0.5615528225898743,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3677999973297119,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6796875,\n",
      "  \"gp_accuracy\": 0.734375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 835.265625,\n",
      "  \"kernel_alignment\": 0.42907679080963135,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 174.06504821777344,\n",
      "  \"relative_weight_norm\": 0.9517662762911514\n",
      "}\n",
      "{\n",
      "  \"step\": 4000,\n",
      "  \"train_loss\": 0.0024962315801531076,\n",
      "  \"test_loss\": 0.5483005046844482,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.37199997901916504,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6640625,\n",
      "  \"gp_accuracy\": 0.7421875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.7523803710938,\n",
      "  \"kernel_alignment\": 0.429076611995697,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 173.84886169433594,\n",
      "  \"relative_weight_norm\": 0.9505841949686621\n",
      "}\n",
      "{\n",
      "  \"step\": 4100,\n",
      "  \"train_loss\": 0.0023676815908402205,\n",
      "  \"test_loss\": 0.5374627113342285,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3707999885082245,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6484375,\n",
      "  \"gp_accuracy\": 0.72265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 833.7384643554688,\n",
      "  \"kernel_alignment\": 0.4288848638534546,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 173.63059997558594,\n",
      "  \"relative_weight_norm\": 0.9493907667334216\n",
      "}\n",
      "{\n",
      "  \"step\": 4200,\n",
      "  \"train_loss\": 0.0019940161146223545,\n",
      "  \"test_loss\": 0.5277361273765564,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3775999844074249,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.671875,\n",
      "  \"gp_accuracy\": 0.7265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.9888916015625,\n",
      "  \"kernel_alignment\": 0.4289049208164215,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 173.42147827148438,\n",
      "  \"relative_weight_norm\": 0.9482473149741953\n",
      "}\n",
      "{\n",
      "  \"step\": 4300,\n",
      "  \"train_loss\": 0.0021444817539304495,\n",
      "  \"test_loss\": 0.5186325311660767,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3773999810218811,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.68359375,\n",
      "  \"gp_accuracy\": 0.72265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 835.7779541015625,\n",
      "  \"kernel_alignment\": 0.42899659276008606,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 173.20501708984375,\n",
      "  \"relative_weight_norm\": 0.9470637318544302\n",
      "}\n",
      "{\n",
      "  \"step\": 4400,\n",
      "  \"train_loss\": 0.0020429750438779593,\n",
      "  \"test_loss\": 0.5078533291816711,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.38519999384880066,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.67578125,\n",
      "  \"gp_accuracy\": 0.7109375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.3945922851562,\n",
      "  \"kernel_alignment\": 0.4287165701389313,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 172.99374389648438,\n",
      "  \"relative_weight_norm\": 0.9459085160165428\n",
      "}\n",
      "{\n",
      "  \"step\": 4500,\n",
      "  \"train_loss\": 0.0020523222628980875,\n",
      "  \"test_loss\": 0.49801385402679443,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3911999762058258,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6640625,\n",
      "  \"gp_accuracy\": 0.734375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 836.051025390625,\n",
      "  \"kernel_alignment\": 0.42840513586997986,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 172.7788848876953,\n",
      "  \"relative_weight_norm\": 0.9447336933808869\n",
      "}\n",
      "{\n",
      "  \"step\": 4600,\n",
      "  \"train_loss\": 0.0023299329914152622,\n",
      "  \"test_loss\": 0.4910987615585327,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3879999816417694,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6484375,\n",
      "  \"gp_accuracy\": 0.72265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 833.7559204101562,\n",
      "  \"kernel_alignment\": 0.42861735820770264,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 172.56765747070312,\n",
      "  \"relative_weight_norm\": 0.9435787278425456\n",
      "}\n",
      "{\n",
      "  \"step\": 4700,\n",
      "  \"train_loss\": 0.0016835430869832635,\n",
      "  \"test_loss\": 0.48039764165878296,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3869999945163727,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.671875,\n",
      "  \"gp_accuracy\": 0.73046875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.5032958984375,\n",
      "  \"kernel_alignment\": 0.42783355712890625,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 172.35374450683594,\n",
      "  \"relative_weight_norm\": 0.9424090780641733\n",
      "}\n",
      "{\n",
      "  \"step\": 4800,\n",
      "  \"train_loss\": 0.0018053811509162188,\n",
      "  \"test_loss\": 0.47008177638053894,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3946000039577484,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66015625,\n",
      "  \"gp_accuracy\": 0.69921875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.3325805664062,\n",
      "  \"kernel_alignment\": 0.42773258686065674,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 172.14068603515625,\n",
      "  \"relative_weight_norm\": 0.9412441005439927\n",
      "}\n",
      "{\n",
      "  \"step\": 4900,\n",
      "  \"train_loss\": 0.0017544860020279884,\n",
      "  \"test_loss\": 0.46103206276893616,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.3959999978542328,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66015625,\n",
      "  \"gp_accuracy\": 0.73046875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.49169921875,\n",
      "  \"kernel_alignment\": 0.4274616837501526,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 171.9302978515625,\n",
      "  \"relative_weight_norm\": 0.940093723830661\n",
      "}\n",
      "{\n",
      "  \"step\": 5000,\n",
      "  \"train_loss\": 0.0016980983782559633,\n",
      "  \"test_loss\": 0.4513302743434906,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.40059998631477356,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65625,\n",
      "  \"gp_accuracy\": 0.7265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 832.5045776367188,\n",
      "  \"kernel_alignment\": 0.4272323250770569,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 171.71632385253906,\n",
      "  \"relative_weight_norm\": 0.9389237403195607\n",
      "}\n",
      "{\n",
      "  \"step\": 5100,\n",
      "  \"train_loss\": 0.0016812460962682962,\n",
      "  \"test_loss\": 0.44431737065315247,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.40619999170303345,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6640625,\n",
      "  \"gp_accuracy\": 0.6953125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 837.4882202148438,\n",
      "  \"kernel_alignment\": 0.42789483070373535,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 171.50253295898438,\n",
      "  \"relative_weight_norm\": 0.9377547580066444\n",
      "}\n",
      "{\n",
      "  \"step\": 5200,\n",
      "  \"train_loss\": 0.0018698435742408037,\n",
      "  \"test_loss\": 0.4353308379650116,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4057999849319458,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.63671875,\n",
      "  \"gp_accuracy\": 0.7109375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.781494140625,\n",
      "  \"kernel_alignment\": 0.4276958703994751,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 171.291259765625,\n",
      "  \"relative_weight_norm\": 0.9365995421687572\n",
      "}\n",
      "{\n",
      "  \"step\": 5300,\n",
      "  \"train_loss\": 0.0016417246079072356,\n",
      "  \"test_loss\": 0.4276352524757385,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.41099998354911804,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.68359375,\n",
      "  \"gp_accuracy\": 0.72265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 834.02392578125,\n",
      "  \"kernel_alignment\": 0.4274100661277771,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 171.08078002929688,\n",
      "  \"relative_weight_norm\": 0.9354486648563335\n",
      "}\n",
      "{\n",
      "  \"step\": 5400,\n",
      "  \"train_loss\": 0.0019920202903449535,\n",
      "  \"test_loss\": 0.420945405960083,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4107999801635742,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66015625,\n",
      "  \"gp_accuracy\": 0.70703125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 833.6064453125,\n",
      "  \"kernel_alignment\": 0.4276341497898102,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 170.86924743652344,\n",
      "  \"relative_weight_norm\": 0.9342920306543523\n",
      "}\n",
      "{\n",
      "  \"step\": 5500,\n",
      "  \"train_loss\": 0.0017937709344550967,\n",
      "  \"test_loss\": 0.41096699237823486,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4131999909877777,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66015625,\n",
      "  \"gp_accuracy\": 0.69140625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 836.2567749023438,\n",
      "  \"kernel_alignment\": 0.42695167660713196,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 170.6590118408203,\n",
      "  \"relative_weight_norm\": 0.9331424882728405\n",
      "}\n",
      "{\n",
      "  \"step\": 5600,\n",
      "  \"train_loss\": 0.0017194533720612526,\n",
      "  \"test_loss\": 0.4041905999183655,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.420199990272522,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.64453125,\n",
      "  \"gp_accuracy\": 0.6875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 832.9818115234375,\n",
      "  \"kernel_alignment\": 0.4268917143344879,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 170.45034790039062,\n",
      "  \"relative_weight_norm\": 0.9320015395090742\n",
      "}\n",
      "{\n",
      "  \"step\": 5700,\n",
      "  \"train_loss\": 0.0018566296203061938,\n",
      "  \"test_loss\": 0.3952367603778839,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.42339998483657837,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66796875,\n",
      "  \"gp_accuracy\": 0.72265625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 831.716552734375,\n",
      "  \"kernel_alignment\": 0.4263949394226074,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 170.23854064941406,\n",
      "  \"relative_weight_norm\": 0.9308434035098171\n",
      "}\n",
      "{\n",
      "  \"step\": 5800,\n",
      "  \"train_loss\": 0.0015217800391837955,\n",
      "  \"test_loss\": 0.3896887004375458,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4251999855041504,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65234375,\n",
      "  \"gp_accuracy\": 0.68359375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 833.3497314453125,\n",
      "  \"kernel_alignment\": 0.42658573389053345,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 170.02850341796875,\n",
      "  \"relative_weight_norm\": 0.9296949457596713\n",
      "}\n",
      "{\n",
      "  \"step\": 5900,\n",
      "  \"train_loss\": 0.0020548009779304266,\n",
      "  \"test_loss\": 0.3823949992656708,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4327999949455261,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66015625,\n",
      "  \"gp_accuracy\": 0.69921875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 831.855712890625,\n",
      "  \"kernel_alignment\": 0.4263390600681305,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 169.81796264648438,\n",
      "  \"relative_weight_norm\": 0.9285437347145196\n",
      "}\n",
      "{\n",
      "  \"step\": 6000,\n",
      "  \"train_loss\": 0.0013527361443266273,\n",
      "  \"test_loss\": 0.3747692406177521,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.43719998002052307,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6640625,\n",
      "  \"gp_accuracy\": 0.703125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 832.6474609375,\n",
      "  \"kernel_alignment\": 0.42580029368400574,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 169.6108856201172,\n",
      "  \"relative_weight_norm\": 0.9274114630016806\n",
      "}\n",
      "{\n",
      "  \"step\": 6100,\n",
      "  \"train_loss\": 0.0017494562780484557,\n",
      "  \"test_loss\": 0.3664190471172333,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.44020000100135803,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.640625,\n",
      "  \"gp_accuracy\": 0.6953125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 829.6765747070312,\n",
      "  \"kernel_alignment\": 0.4255119860172272,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 169.4019317626953,\n",
      "  \"relative_weight_norm\": 0.9262689290074564\n",
      "}\n",
      "{\n",
      "  \"step\": 6200,\n",
      "  \"train_loss\": 0.0018010169733315706,\n",
      "  \"test_loss\": 0.36019670963287354,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.438400000333786,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6328125,\n",
      "  \"gp_accuracy\": 0.703125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 830.7573852539062,\n",
      "  \"kernel_alignment\": 0.4256075322628021,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 169.19093322753906,\n",
      "  \"relative_weight_norm\": 0.9251152149668449\n",
      "}\n",
      "{\n",
      "  \"step\": 6300,\n",
      "  \"train_loss\": 0.00126892258413136,\n",
      "  \"test_loss\": 0.3541964888572693,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.44099998474121094,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65234375,\n",
      "  \"gp_accuracy\": 0.6796875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 830.5438232421875,\n",
      "  \"kernel_alignment\": 0.425303190946579,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 168.98097229003906,\n",
      "  \"relative_weight_norm\": 0.923967174382609\n",
      "}\n",
      "{\n",
      "  \"step\": 6400,\n",
      "  \"train_loss\": 0.0013727538753300905,\n",
      "  \"test_loss\": 0.34756818413734436,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.44759997725486755,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66796875,\n",
      "  \"gp_accuracy\": 0.6875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 832.4266967773438,\n",
      "  \"kernel_alignment\": 0.42544135451316833,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 168.77334594726562,\n",
      "  \"relative_weight_norm\": 0.9228318990752182\n",
      "}\n",
      "{\n",
      "  \"step\": 6500,\n",
      "  \"train_loss\": 0.0014145855093374848,\n",
      "  \"test_loss\": 0.3408549726009369,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4503999948501587,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65234375,\n",
      "  \"gp_accuracy\": 0.68359375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 829.46142578125,\n",
      "  \"kernel_alignment\": 0.4248935282230377,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 168.56805419921875,\n",
      "  \"relative_weight_norm\": 0.9217093890446726\n",
      "}\n",
      "{\n",
      "  \"step\": 6600,\n",
      "  \"train_loss\": 0.0012858142144978046,\n",
      "  \"test_loss\": 0.33518001437187195,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.45179998874664307,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.640625,\n",
      "  \"gp_accuracy\": 0.69140625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 831.2716674804688,\n",
      "  \"kernel_alignment\": 0.42531758546829224,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 168.35960388183594,\n",
      "  \"relative_weight_norm\": 0.9205696083454541\n",
      "}\n",
      "{\n",
      "  \"step\": 6700,\n",
      "  \"train_loss\": 0.0013183938572183251,\n",
      "  \"test_loss\": 0.3288351595401764,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.45559999346733093,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65625,\n",
      "  \"gp_accuracy\": 0.68359375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 827.7955322265625,\n",
      "  \"kernel_alignment\": 0.4242437481880188,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 168.15451049804688,\n",
      "  \"relative_weight_norm\": 0.9194481829462743\n",
      "}\n",
      "{\n",
      "  \"step\": 6800,\n",
      "  \"train_loss\": 0.0016309440834447742,\n",
      "  \"test_loss\": 0.3226172626018524,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.46219998598098755,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.63671875,\n",
      "  \"gp_accuracy\": 0.69921875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 830.7279663085938,\n",
      "  \"kernel_alignment\": 0.4250217080116272,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 167.94964599609375,\n",
      "  \"relative_weight_norm\": 0.9183280090448244\n",
      "}\n",
      "{\n",
      "  \"step\": 6900,\n",
      "  \"train_loss\": 0.0012532788095995784,\n",
      "  \"test_loss\": 0.3168240785598755,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.462799996137619,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65234375,\n",
      "  \"gp_accuracy\": 0.68359375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 830.2504272460938,\n",
      "  \"kernel_alignment\": 0.42454850673675537,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 167.7361297607422,\n",
      "  \"relative_weight_norm\": 0.917160528529184\n",
      "}\n",
      "{\n",
      "  \"step\": 7000,\n",
      "  \"train_loss\": 0.001162200584076345,\n",
      "  \"test_loss\": 0.3104839324951172,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.462799996137619,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.66015625,\n",
      "  \"gp_accuracy\": 0.66796875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 832.0005493164062,\n",
      "  \"kernel_alignment\": 0.42491403222084045,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 167.53311157226562,\n",
      "  \"relative_weight_norm\": 0.9160504500427553\n",
      "}\n",
      "{\n",
      "  \"step\": 7100,\n",
      "  \"train_loss\": 0.0012247830163687468,\n",
      "  \"test_loss\": 0.30455538630485535,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4705999791622162,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6640625,\n",
      "  \"gp_accuracy\": 0.69921875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 827.9127807617188,\n",
      "  \"kernel_alignment\": 0.4244963526725769,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 167.3251495361328,\n",
      "  \"relative_weight_norm\": 0.9149133392053607\n",
      "}\n",
      "{\n",
      "  \"step\": 7200,\n",
      "  \"train_loss\": 0.0011541270650923252,\n",
      "  \"test_loss\": 0.298308402299881,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4697999954223633,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.64453125,\n",
      "  \"gp_accuracy\": 0.67578125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 827.2123413085938,\n",
      "  \"kernel_alignment\": 0.42383959889411926,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 167.11883544921875,\n",
      "  \"relative_weight_norm\": 0.9137852391516214\n",
      "}\n",
      "{\n",
      "  \"step\": 7300,\n",
      "  \"train_loss\": 0.0013129370054230094,\n",
      "  \"test_loss\": 0.2940179705619812,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4795999825000763,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65234375,\n",
      "  \"gp_accuracy\": 0.66015625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 824.8352661132812,\n",
      "  \"kernel_alignment\": 0.4233963191509247,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 166.9164276123047,\n",
      "  \"relative_weight_norm\": 0.9126784979924725\n",
      "}\n",
      "{\n",
      "  \"step\": 7400,\n",
      "  \"train_loss\": 0.0011880447855219245,\n",
      "  \"test_loss\": 0.28916528820991516,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4797999858856201,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6640625,\n",
      "  \"gp_accuracy\": 0.6953125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 825.9342041015625,\n",
      "  \"kernel_alignment\": 0.42350414395332336,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 166.70916748046875,\n",
      "  \"relative_weight_norm\": 0.9115452250814495\n",
      "}\n",
      "{\n",
      "  \"step\": 7500,\n",
      "  \"train_loss\": 0.0011945971054956317,\n",
      "  \"test_loss\": 0.28380024433135986,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.48579999804496765,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6640625,\n",
      "  \"gp_accuracy\": 0.6953125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 825.2885131835938,\n",
      "  \"kernel_alignment\": 0.423168808221817,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 166.50576782226562,\n",
      "  \"relative_weight_norm\": 0.910433060765471\n",
      "}\n",
      "{\n",
      "  \"step\": 7600,\n",
      "  \"train_loss\": 0.0010315170511603355,\n",
      "  \"test_loss\": 0.2776618003845215,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4901999831199646,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.65234375,\n",
      "  \"gp_accuracy\": 0.69140625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 824.8860473632812,\n",
      "  \"kernel_alignment\": 0.4235340356826782,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 166.30099487304688,\n",
      "  \"relative_weight_norm\": 0.9093133874631132\n",
      "}\n",
      "{\n",
      "  \"step\": 7700,\n",
      "  \"train_loss\": 0.0011892145266756415,\n",
      "  \"test_loss\": 0.2736322283744812,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.4919999837875366,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6484375,\n",
      "  \"gp_accuracy\": 0.6640625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 827.8721313476562,\n",
      "  \"kernel_alignment\": 0.42312970757484436,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 166.0973358154297,\n",
      "  \"relative_weight_norm\": 0.9081998047830407\n",
      "}\n",
      "{\n",
      "  \"step\": 7800,\n",
      "  \"train_loss\": 0.0010259492555633187,\n",
      "  \"test_loss\": 0.26839467883110046,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.49879997968673706,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.671875,\n",
      "  \"gp_accuracy\": 0.67578125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 825.6605224609375,\n",
      "  \"kernel_alignment\": 0.4230910837650299,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 165.89578247070312,\n",
      "  \"relative_weight_norm\": 0.9070977358820835\n",
      "}\n",
      "{\n",
      "  \"step\": 7900,\n",
      "  \"train_loss\": 0.0010658546816557646,\n",
      "  \"test_loss\": 0.26432737708091736,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.49619999527931213,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.64453125,\n",
      "  \"gp_accuracy\": 0.6953125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 824.6104125976562,\n",
      "  \"kernel_alignment\": 0.42308300733566284,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 165.69302368164062,\n",
      "  \"relative_weight_norm\": 0.9059890757597489\n",
      "}\n",
      "{\n",
      "  \"step\": 8000,\n",
      "  \"train_loss\": 0.0010426733642816544,\n",
      "  \"test_loss\": 0.2591627836227417,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.49699997901916504,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.640625,\n",
      "  \"gp_accuracy\": 0.6796875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 823.0531616210938,\n",
      "  \"kernel_alignment\": 0.4222618639469147,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 165.4876251220703,\n",
      "  \"relative_weight_norm\": 0.9048659816969291\n",
      "}\n",
      "{\n",
      "  \"step\": 8100,\n",
      "  \"train_loss\": 0.0008904170244932175,\n",
      "  \"test_loss\": 0.25398096442222595,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5011999607086182,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.625,\n",
      "  \"gp_accuracy\": 0.671875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 821.6834716796875,\n",
      "  \"kernel_alignment\": 0.4219876229763031,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 165.2860870361328,\n",
      "  \"relative_weight_norm\": 0.9037639962291539\n",
      "}\n",
      "{\n",
      "  \"step\": 8200,\n",
      "  \"train_loss\": 0.000985204242169857,\n",
      "  \"test_loss\": 0.24977315962314606,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5019999742507935,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.63671875,\n",
      "  \"gp_accuracy\": 0.671875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 820.8218994140625,\n",
      "  \"kernel_alignment\": 0.42172378301620483,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 165.08502197265625,\n",
      "  \"relative_weight_norm\": 0.9026645971900205\n",
      "}\n",
      "{\n",
      "  \"step\": 8300,\n",
      "  \"train_loss\": 0.001104189781472087,\n",
      "  \"test_loss\": 0.24570868909358978,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5077999830245972,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.61328125,\n",
      "  \"gp_accuracy\": 0.66015625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 820.3468627929688,\n",
      "  \"kernel_alignment\": 0.422274112701416,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 164.88111877441406,\n",
      "  \"relative_weight_norm\": 0.9015496795790362\n",
      "}\n",
      "{\n",
      "  \"step\": 8400,\n",
      "  \"train_loss\": 0.0008827945566736162,\n",
      "  \"test_loss\": 0.24127694964408875,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5090000033378601,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.64453125,\n",
      "  \"gp_accuracy\": 0.671875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 817.6464233398438,\n",
      "  \"kernel_alignment\": 0.42113977670669556,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 164.68121337890625,\n",
      "  \"relative_weight_norm\": 0.9004566214617343\n",
      "}\n",
      "{\n",
      "  \"step\": 8500,\n",
      "  \"train_loss\": 0.0010510393185541034,\n",
      "  \"test_loss\": 0.23726175725460052,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5101999640464783,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.62890625,\n",
      "  \"gp_accuracy\": 0.671875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 819.6563720703125,\n",
      "  \"kernel_alignment\": 0.4212383031845093,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 164.47988891601562,\n",
      "  \"relative_weight_norm\": 0.899355804058507\n",
      "}\n",
      "{\n",
      "  \"step\": 8600,\n",
      "  \"train_loss\": 0.0009309261222369969,\n",
      "  \"test_loss\": 0.23275986313819885,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5157999992370605,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.62109375,\n",
      "  \"gp_accuracy\": 0.6484375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 815.1988525390625,\n",
      "  \"kernel_alignment\": 0.42079195380210876,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 164.28094482421875,\n",
      "  \"relative_weight_norm\": 0.8982680022316708\n",
      "}\n",
      "{\n",
      "  \"step\": 8700,\n",
      "  \"train_loss\": 0.0009306547581218183,\n",
      "  \"test_loss\": 0.22819145023822784,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5135999917984009,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6328125,\n",
      "  \"gp_accuracy\": 0.671875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 820.0433959960938,\n",
      "  \"kernel_alignment\": 0.4213837683200836,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 164.0796661376953,\n",
      "  \"relative_weight_norm\": 0.8971674351279895\n",
      "}\n",
      "{\n",
      "  \"step\": 8800,\n",
      "  \"train_loss\": 0.000895315024536103,\n",
      "  \"test_loss\": 0.2244250625371933,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.520799994468689,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.62890625,\n",
      "  \"gp_accuracy\": 0.6796875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 815.1708374023438,\n",
      "  \"kernel_alignment\": 0.42061614990234375,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 163.88084411621094,\n",
      "  \"relative_weight_norm\": 0.8960803007666092\n",
      "}\n",
      "{\n",
      "  \"step\": 8900,\n",
      "  \"train_loss\": 0.0010263209696859121,\n",
      "  \"test_loss\": 0.2216876596212387,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5230000019073486,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.62890625,\n",
      "  \"gp_accuracy\": 0.6875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 815.1561279296875,\n",
      "  \"kernel_alignment\": 0.42095518112182617,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 163.6790313720703,\n",
      "  \"relative_weight_norm\": 0.894976813501558\n",
      "}\n",
      "{\n",
      "  \"step\": 9000,\n",
      "  \"train_loss\": 0.0008864632109180093,\n",
      "  \"test_loss\": 0.2175721377134323,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5259999632835388,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.62109375,\n",
      "  \"gp_accuracy\": 0.6796875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 815.4710083007812,\n",
      "  \"kernel_alignment\": 0.420486718416214,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 163.47950744628906,\n",
      "  \"relative_weight_norm\": 0.893885841213806\n",
      "}\n",
      "{\n",
      "  \"step\": 9100,\n",
      "  \"train_loss\": 0.0011203635949641466,\n",
      "  \"test_loss\": 0.2139059454202652,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5325999855995178,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.625,\n",
      "  \"gp_accuracy\": 0.66796875,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 811.9502563476562,\n",
      "  \"kernel_alignment\": 0.42024287581443787,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 163.27993774414062,\n",
      "  \"relative_weight_norm\": 0.8927946186265079\n",
      "}\n",
      "{\n",
      "  \"step\": 9200,\n",
      "  \"train_loss\": 0.0006573981372639537,\n",
      "  \"test_loss\": 0.2098214030265808,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5360000133514404,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.62890625,\n",
      "  \"gp_accuracy\": 0.64453125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 808.947509765625,\n",
      "  \"kernel_alignment\": 0.41994383931159973,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 163.08424377441406,\n",
      "  \"relative_weight_norm\": 0.8917245880674364\n",
      "}\n",
      "{\n",
      "  \"step\": 9300,\n",
      "  \"train_loss\": 0.0008474015048705041,\n",
      "  \"test_loss\": 0.20700667798519135,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5375999808311462,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.60546875,\n",
      "  \"gp_accuracy\": 0.65625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 812.1988525390625,\n",
      "  \"kernel_alignment\": 0.41989827156066895,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 162.88592529296875,\n",
      "  \"relative_weight_norm\": 0.8906402070010618\n",
      "}\n",
      "{\n",
      "  \"step\": 9400,\n",
      "  \"train_loss\": 0.000803318340331316,\n",
      "  \"test_loss\": 0.20377619564533234,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5429999828338623,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.64453125,\n",
      "  \"gp_accuracy\": 0.6640625,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 810.8726806640625,\n",
      "  \"kernel_alignment\": 0.4196748733520508,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 162.69117736816406,\n",
      "  \"relative_weight_norm\": 0.889575349299274\n",
      "}\n",
      "{\n",
      "  \"step\": 9500,\n",
      "  \"train_loss\": 0.0007911932771094143,\n",
      "  \"test_loss\": 0.20046302676200867,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.545199990272522,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.640625,\n",
      "  \"gp_accuracy\": 0.64453125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 808.114013671875,\n",
      "  \"kernel_alignment\": 0.41998326778411865,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 162.4933319091797,\n",
      "  \"relative_weight_norm\": 0.8884935546615412\n",
      "}\n",
      "{\n",
      "  \"step\": 9600,\n",
      "  \"train_loss\": 0.0007767266943119466,\n",
      "  \"test_loss\": 0.19675509631633759,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5493999719619751,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.625,\n",
      "  \"gp_accuracy\": 0.6484375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 805.4683227539062,\n",
      "  \"kernel_alignment\": 0.4192400872707367,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 162.29660034179688,\n",
      "  \"relative_weight_norm\": 0.887417850646094\n",
      "}\n",
      "{\n",
      "  \"step\": 9700,\n",
      "  \"train_loss\": 0.0008206941420212388,\n",
      "  \"test_loss\": 0.19318334758281708,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5483999848365784,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.62890625,\n",
      "  \"gp_accuracy\": 0.65234375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 805.435302734375,\n",
      "  \"kernel_alignment\": 0.41895097494125366,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 162.10400390625,\n",
      "  \"relative_weight_norm\": 0.8863647570229672\n",
      "}\n",
      "{\n",
      "  \"step\": 9800,\n",
      "  \"train_loss\": 0.0007813181728124619,\n",
      "  \"test_loss\": 0.18994812667369843,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5529999732971191,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6328125,\n",
      "  \"gp_accuracy\": 0.65234375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 804.83984375,\n",
      "  \"kernel_alignment\": 0.4187484681606293,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 161.90997314453125,\n",
      "  \"relative_weight_norm\": 0.885303820680733\n",
      "}\n",
      "{\n",
      "  \"step\": 9900,\n",
      "  \"train_loss\": 0.000701363489497453,\n",
      "  \"test_loss\": 0.18733640015125275,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5529999732971191,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6171875,\n",
      "  \"gp_accuracy\": 0.64453125,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 804.1661987304688,\n",
      "  \"kernel_alignment\": 0.4180937111377716,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 161.71478271484375,\n",
      "  \"relative_weight_norm\": 0.8842365434166672\n",
      "}\n",
      "{\n",
      "  \"step\": 10000,\n",
      "  \"train_loss\": 0.000752260850276798,\n",
      "  \"test_loss\": 0.1835775077342987,\n",
      "  \"training_acc\": 1.0,\n",
      "  \"test_acc\": 0.5618000030517578,\n",
      "  \"svm_train_accuracy\": 1.0,\n",
      "  \"svm_accuracy\": 0.6328125,\n",
      "  \"gp_accuracy\": 0.65234375,\n",
      "  \"dots\": 2560,\n",
      "  \"dots_2\": 2560,\n",
      "  \"dots_3\": 805.7030639648438,\n",
      "  \"kernel_alignment\": 0.418387770652771,\n",
      "  \"kernel\": null,\n",
      "  \"weight_norm\": 161.51976013183594,\n",
      "  \"relative_weight_norm\": 0.8831701839176034\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "all_metrics = []\n",
    "for step in range(0, total_steps + 1, step_distance):\n",
    "    if step > 0:\n",
    "        state = restore_manager.restore(\n",
    "            step, args=ocp.args.StandardRestore(state)\n",
    "        )\n",
    "    train_loss, train_acc, test_loss, test_acc = eval_checkpoint(\n",
    "        state, config, train_loader, test_loader, scale_training_data\n",
    "    )\n",
    "    svm_train_acc, svm_test_acc = compute_svm_accuracy(\n",
    "        lambda x1, x2: kernel_fn(x1, x2, state.params),\n",
    "        analysis_X_train,\n",
    "        analysis_Y_train,\n",
    "        analysis_X_test,\n",
    "        analysis_Y_test,\n",
    "    )\n",
    "    gp_acc = compute_gp_accuracy(\n",
    "        lambda x1, x2: kernel_fn(x1, x2, state.params),\n",
    "        analysis_X_train,\n",
    "        analysis_Y_train,\n",
    "        analysis_X_test,\n",
    "        analysis_Y_test,\n",
    "        ds_train.features[\"y\"].num_classes,\n",
    "    )\n",
    "\n",
    "    kernel_X = ds_test[\"x\"][:kernel_samples]\n",
    "    kernel_Y = ds_test[\"y\"][:kernel_samples]\n",
    "    kernel = kernel_trace_axes_fn(kernel_X, None, state.params)\n",
    "    dots_1, dots_2, dots_3 = compute_dots(kernel)\n",
    "    kernel_alignment = compute_kernel_alignment(kernel, kernel_Y)\n",
    "\n",
    "    all_metrics.append(\n",
    "        {\n",
    "            \"step\": step,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"training_acc\": train_acc,\n",
    "            \"test_acc\": test_acc,\n",
    "            \"svm_train_accuracy\": svm_train_acc,\n",
    "            \"svm_accuracy\": svm_test_acc,\n",
    "            \"gp_accuracy\": gp_acc,\n",
    "            \"dots\": dots_1.item(),\n",
    "            \"dots_2\": dots_2.item(),\n",
    "            \"dots_3\": dots_3.item(),\n",
    "            \"kernel_alignment\": kernel_alignment.item(),\n",
    "            \"kernel\": kernel.tolist() if add_kernel else None,\n",
    "            \"weight_norm\": optax.global_norm(state.params).item(),\n",
    "            \"relative_weight_norm\": optax.global_norm(state.params).item() / initial_weight_norm,\n",
    "        }\n",
    "    )\n",
    "    print(json.dumps(all_metrics[-1], indent=2))\n",
    "\n",
    "out_file = Path(logs_base_path, \"results\", f\"{experiment_json_file_name}.json\")\n",
    "out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(out_file, \"w\") as f:\n",
    "    # Convert list[dict] -> dict[list]\n",
    "    metrics_json = {k: [d[k] for d in all_metrics] for k in all_metrics[0]}\n",
    "    json.dump(metrics_json, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
